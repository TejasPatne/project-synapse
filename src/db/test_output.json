[
    {
        "__EMPTY": 1,
        "A": "grpno",
        "B": "title",
        "C": "member1",
        "D": "member2",
        "E": "member3",
        "F": "member4",
        "G": "guide",
        "H": "coguide",
        "I": "description",
        "J": "github",
        "K": "demo",
        "L": "domain",
        "M": "Research Paper Doc",
        "N": "Fundings Received",
        "O": "member1 photo",
        "P": "member2 photo",
        "Q": "member3 photo",
        "R": "member4 photo",
        "S": "guide photo",
        "T": "coguide photo"
    },
    {
        "__EMPTY": 2,
        "A": 1,
        "B": "Detecting cyberbullying using Deep learning",
        "C": "Prasad Jawale",
        "D": "Anushka Kulkarni",
        "E": "Subrato Tapaswi",
        "F": "Lakshman Bhojwani",
        "G": "Dr. Vijayalaxmi",
        "H": "Mamata C",
        "I": "The project, titled \"Detecting Cyberbullying using Deep Learning,\" aims to investigate cyber aggression on Twitter, focusing on identifying derogatory tweets based on gender, race, or sexual orientation. It seeks to develop an automated system capable of accurately analyzing text-based content across online platforms to detect instances of cyberbullying.\n\nLeveraging a dataset of approximately 110,000 instances, the study explores various detection methods, including non-deep learning approaches such as SVM, L2 regularization, and random forest, as well as deep learning techniques utilizing BERT. Additionally, an ensemble learning approach combining BERT and LSTM is planned.\n\nThe classification system categorizes tweets into six major categories: gender, age, religion, not cyberbullying, and ethnicity. To evaluate the effectiveness of these methods, a test dataset of 20,000 tweets will be employed, facilitating a comparative analysis to determine which model best identifies and classifies cyberbullying tweets accurately.",
        "J": "https://github.com/Tydos/Cyberbullying-Detection/tree/main",
        "K": "https://www.youtube.com/embed/tp65dH-YIBg?si=817PgYnh9bNJm9dS",
        "L": "Deep Learning",
        "M": "https://docs.google.com/document/d/1K4-byLQrLmqAYYjZs4Te-WuVD1xgoqW7/edit",
        "N": null,
        "O": "https://media.licdn.com/dms/image/C4D03AQEo4bsvzTnLiQ/profile-displayphoto-shrink_400_400/0/1662101524731?e=1716422400&v=beta&t=nVWBD-j6jzxRMqoi68-IqvyTYOUY362evosUvlefRiU",
        "P": "https://media.licdn.com/dms/image/D4D03AQFpnIgP_yWpMQ/profile-displayphoto-shrink_400_400/0/1661488412068?e=1716422400&v=beta&t=Xo523AtSgqlrbnaM42BJRn-VOUSILAdSgaUp4kIe6kg",
        "Q": "https://media.licdn.com/dms/image/C5603AQF2xxD2ZwXU-A/profile-displayphoto-shrink_200_200/0/1643320265523?e=2147483647&v=beta&t=Zglhi9Frgcq2MVhxV86XQIAHDOnp33keLNFNW3-uLMk",
        "R": "Lakshman Bhojwani",
        "S": null,
        "T": "Mamata C"
    },
    {
        "__EMPTY": 3,
        "A": 2,
        "B": "SecurGAN",
        "C": "Arunim Chakraborty",
        "D": "Satyam Dubey",
        "E": "Prathmesh Pawar",
        "F": "Yash Sarang",
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": "The project, titled \"SecurGAN: AI-Powered Facial Inpainting for Enhanced Law Enforcement and Security,\" aims to develop a system utilizing AI-powered facial inpainting techniques with Generative Adversarial Neural Networks (GANs). This system reconstructs the facial features of an unknown person who has covered their face, generating an accurate representation based on visible features and contextual information in the image. Its goal is to provide law enforcement agencies with a tool that assists in identifying individuals involved in criminal activities or other security-related incidents where their faces are obscured, enhancing the capabilities of law enforcement personnel in gathering information and solving cases effectively through advanced machine learning algorithms.",
        "J": "https://github.com/prathmeshppawar/Major-Project",
        "K": "https://www.youtube.com/embed/55NLy-MzmM4?si=QmWXQ2xAkelkCsBc",
        "L": "Computer Vision",
        "M": "https://drive.google.com/file/d/1mO4MC2TRHs4Alb9EvCbCvigf42h3LNOB/view?usp=sharing",
        "N": null,
        "O": "https://media.licdn.com/dms/image/C5603AQFJQhH7sl6MYw/profile-displayphoto-shrink_400_400/0/1652889170591?e=1716422400&v=beta&t=JqV4RTC_9pfH-9kf9kmC2Yn3jUnrJOV4QFvGv3IIlqQ",
        "P": "https://media.licdn.com/dms/image/C5603AQEpe0uEcU0nug/profile-displayphoto-shrink_800_800/0/1657954640571?e=1716422400&v=beta&t=gn5O2JDPGFXvK97LuCOxQbvStJyOdAOXf3citJTWsDk",
        "Q": "https://media.licdn.com/dms/image/C4D03AQHJi3HY2BphPw/profile-displayphoto-shrink_400_400/0/1662209363149?e=1716422400&v=beta&t=tVTvuQCRVcmv1kFTLjDb4iR3Vyb8eDMyJb1wvesfDio",
        "R": "https://media.licdn.com/dms/image/C4D03AQF0ykYJLs_Xxg/profile-displayphoto-shrink_400_400/0/1652212779374?e=1716422400&v=beta&t=nyjncyqx9gdwRgKWnx1-eH6XqfbJNn70jujcqHIn7sM",
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 4,
        "A": 3,
        "B": "Location Predictor",
        "C": "Akanksha Singh",
        "D": "Ashish Gupta",
        "E": "Abhijay Sharangdhar",
        "F": "Hrishikesh Kudale",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": "In Mumbai&#39;s lively coffee culture, selecting a new cafe location like AbCoffee is critical but challenging. Traditional methods of site selection can be risky. Our project uses data-driven spatial analysis techniques to pinpoint optimal expansion locations.\n\nWe employ clustering analysis, specifically the DBSCAN algorithm, to uncover cafe clusters based on proximity. This helps us understand distribution patterns and success factors like density and proximity to transportation hubs. We also analyze broader market dynamics such as real estate pricing and transportation accessibility. Integrating property price data and transportation proximity provides insights into the market landscape. Our approach is scalable and adaptable beyond Mumbai, making it applicable to other cities with minimal adjustments. This flexibility allows businesses to replicate our insights in different market environments. Our recommendations provide actionable insights for businesses like AbCoffee, highlighting potential high-yield locations with less competition. This data-driven approach minimizes risks and maximizes success in competitive markets.\n\nIn summary, our project leverages data science to guide strategic coffee shop expansion decisions, empowering businesses to thrive in dynamic urban environments.\n\n\n\n\n\n\n",
        "J": "https://github.com/akanksha2828/Major-Project/blob/master/abcoffee_prediction.ipynb",
        "K": "https://www.youtube.com/embed/8bYeRJHqj4o?si=NBm4D4NArcNTgWjc",
        "L": null,
        "M": "https://docs.google.com/document/d/1EiXdgmJC_ZDCdTDf1oOkoY48fN_wcEdk9I5ddA2MuD0/edit?usp=drivesdk",
        "N": null,
        "O": "Akanksha Singh",
        "P": "Ashish Gupta",
        "Q": "https://media.licdn.com/dms/image/D4D03AQGvPD8GyBUbug/profile-displayphoto-shrink_800_800/0/1681057643897?e=1716422400&v=beta&t=8CY90HB476aLpkJtczKUmcwBhVlnWZc7HeMWKc-hkBU",
        "R": "Hrishikesh Kudale",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 5,
        "A": 4,
        "B": "Language Text Summarisation",
        "C": "Siddhant Dongre",
        "D": "Shubham Hadawle",
        "E": "Pranav Kotkar",
        "F": "Om Bhatia",
        "G": "Amit Singh",
        "H": "Akansha P",
        "I": "When it comes to extracting pertinent information from lengthy textual materials, text summary is essential. Nonetheless, there are very few language models available for use with texts written in regional or native tongues. Regional languages frequently face issues such as a lack of digital material, resource constraints, linguistic inflections, and structural variance. This work attempts to fill up those similar gaps so that we can model text summarizers in regional languages. In this work, we investigate the efficacy of self-attention mechanisms for abstractive text summarization in two Indo-Aryan languages, Gujarati and Hindi, by particularly utilizing a Conventional Transformer. Our methodology entails using the ILSUM dataset to train a specially constructed Transformer model. Articles, headlines, and summaries are used to curate corpora for the Indian Language Summarization project (ILSUM).",
        "J": "https://github.com/shubham-hadawle/Text-Summarization-for-Indo-Aryan-Languages-using-Self-Attention-Mechanism",
        "K": "https://drive.google.com/file/d/15_TY20xqhdA_Mgdqx8G4jSZC1yqNbCUL/view?usp=sharing",
        "L": "NLP",
        "M": null,
        "N": null,
        "O": "Siddhant Dongre",
        "P": "https://media.licdn.com/dms/image/C5603AQERpRlZZoxhvg/profile-displayphoto-shrink_400_400/0/1642254667781?e=1716422400&v=beta&t=cixTN9AsVGP2UZsPw3jE2Dk86cSAlZTlVzad-9qlZ6o",
        "Q": "https://media.licdn.com/dms/image/D4D03AQG-KSd4kEJbMQ/profile-displayphoto-shrink_400_400/0/1688983708371?e=1716422400&v=beta&t=ftg1rX8ZqRctthOmDuyHk_plP50SfeTsfFR-EPB4Q_Y",
        "R": "Om Bhatia",
        "S": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
        "T": "Akansha P"
    },
    {
        "__EMPTY": 6,
        "A": 5,
        "B": "AI Based smart meter",
        "C": "Sarthak Bansod",
        "D": "Sheryl Bellary",
        "E": "Sheetal Dixit",
        "F": "Soham Jadiye",
        "G": "Ajinkya W",
        "H": "Kusum K",
        "I": "The AI-based smart meter project aims to monitor electricity consumption, humidity, and CO2 levels within a room using IoT devices. Data collected from these devices is then displayed on both a website and a mobile application for user accessibility. Additionally, machine learning techniques, such as ARIMA,LSTM,RNN are employed to forecast future electricity consumption patterns. This integration of IoT and machine learning enables users to optimize energy usage and make informed decisions about electricity consumption.",
        "J": "https://github.com/SohamJadiye/AI-Based-Smart-Meter",
        "K": null,
        "L": "Deep Learning",
        "M": "https://drive.google.com/file/d/1v1G_-t19GgEu3ocn3sm2dtX2UIQWeNUf/view?usp=sharing",
        "N": null,
        "O": "Sarthak Bansod",
        "P": "Sheryl Bellary",
        "Q": "Sheetal Dixit",
        "R": "https://media.licdn.com/dms/image/D4D03AQFcjBoXI7k7kA/profile-displayphoto-shrink_400_400/0/1695790820929?e=1716422400&v=beta&t=Pm-1KNJz0-4Xdp5-APGcQb-OEOoUIDupb_OiMtvIotc",
        "S": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
        "T": "Kusum K"
    },
    {
        "__EMPTY": 7,
        "A": 6,
        "B": "Visual Speech Recognition using AI",
        "C": "Tejas Patne",
        "D": "Arya Kurup",
        "E": "Rupesh Dhirwani",
        "F": "Akshat Tiwari",
        "G": "Dr. Vijayalaxmi",
        "H": "Mamata C",
        "I": "Visual speech recognition using deep learning involves the utilization of neural network architectures to predict speech content solely based on visual cues extracted from videos of speakers. This technology holds significant potential for various applications, including improving speech recognition accuracy in noisy environments, aiding individuals with hearing impairments, enhancing human-computer interaction in multimedia systems, and facilitating automatic transcription of videos. The first step involves preprocessing the video data to extract relevant visual features. This typically involves techniques such as face detection and tracking, lip region segmentation, and feature extraction. Common features include lip movements, facial expressions, and head gestures. LipNet is a deep learning architecture specifically designed for lip reading. It combines convolutional neural networks (CNNs) for feature extraction from lip images with recurrent neural networks (RNNs) such as Long Short-Term Memory (LSTM) networks for sequence modeling and prediction.STCNNs are specialized architectures designed to capture both spatial and temporal information from video data. They typically consist of 3D convolutional layers followed by fully connected layers for classification or prediction tasks. Bi-LSTMs are recurrent neural networks that process input sequences in both forward and backward directions, enabling them to capture temporal dependencies effectively. They are often used for sequence modeling tasks such as speech recognition and natural languageprocessing. Once the architecture is selected, the model is trained using labeled video data, where the input consists of visual features extracted from video frames, and the output is the corresponding speech content. The training process involves optimizing the model parameters to minimize prediction errors using techniques like stochastic gradient descent (SGD) or adaptive optimization algorithms like Adam. After training, the model is evaluated on a separate test set to assess its performance. Common evaluation metrics include accuracy, precision, recall, and F1 score. Additionally, qualitative assessment through visual inspection of predictions can provide insights into the model&#39;s strengths and weaknesses. Once the model is trained and evaluated satisfactorily, it can be deployed for real-world applications. These applications may include real-time speech recognition in videos, automatic transcription of spoken content, enhancing accessibility for individuals with hearing impairments, and integrating with multimedia systems for interactive experiences. Overall, visual speech recognition using deep learning holds promise for advancing the state-of-the-art in speech processing and multimedia technology, with potential benefits across various domains.\n",
        "J": "https://github.com/TejasPatne/visual-speech-recognition/tree/main",
        "K": "https://www.youtube.com/embed/hAyl4jf-3bo?si=zA6kazz8lPe0ZONg",
        "L": "Deep Learning",
        "M": "https://docs.google.com/document/d/1S_HG9tPAJ6JyKPIsGSs27Trmb5kxH2qBpl5t7Ejcbyk/edit?usp=sharing",
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQGhRusuZJ8hLQ/profile-displayphoto-shrink_200_200/0/1675172921760?e=2147483647&v=beta&t=6Tp6UPcjCsLP1Lj0P1EyCO1RRsVhXIldXIo4C24l3ME",
        "P": "https://media.licdn.com/dms/image/D4D03AQEql3wgymmxGQ/profile-displayphoto-shrink_400_400/0/1711118147801?e=1716422400&v=beta&t=q4-oZ9KFPpYb0M2N4ij5sK17Efpdv6Yyf4_FhqVaHTE",
        "Q": "https://media.licdn.com/dms/image/D4D03AQExokynmRzyJQ/profile-displayphoto-shrink_400_400/0/1711130756589?e=1716422400&v=beta&t=xRjzQLqiKEN6FhHVJfSt2JW9Ef6vwl4oZeSeQ5JjnWU",
        "R": "https://media.licdn.com/dms/image/D4D35AQHEncAi_NxImw/profile-framedphoto-shrink_400_400/0/1663438705871?e=1711760400&v=beta&t=oDKFOAXIPlqurQhnx2IqCxNMAjdVngDjVEIc2LkHFt0",
        "S": null,
        "T": "Mamata C"
    },
    {
        "__EMPTY": 8,
        "A": 7,
        "B": "Maatri Shakthi",
        "C": "Vemburaj Konar",
        "D": "Mayur Pimpude",
        "E": "Heramb Pawar",
        "F": "Deepak Prasad",
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": "The objective is to leverage machine learning and Deep Learning to accurately assess the malnutrition vulnerability of infants using demographic and socio-economic attributes from the census data.\nThe creation of a user-friendly dashboard will allow healthcare practitioners and policymakers to efficiently interpret and explore the prediction outcomes, facilitating targeted interventions and evidence-based decision-making to address malnutrition and its associated challenges among newborn\n",
        "J": "https://github.com/MayurPimpude/BE-Project",
        "K": "https://www.youtube.com/embed/xdJ_f735Ft8?si=cMA9YvJsFa1gH-rL",
        "L": "Deep Learning",
        "M": "https://docs.google.com/document/d/1gzMElYVN55oS-qHLVD7zLVYQFby8BTOn2urxl3YJRT4/edit?usp=sharing",
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQHpbb7DZ0teyw/profile-displayphoto-shrink_400_400/0/1693139740090?e=1716422400&v=beta&t=Vz5dRLjSSAOSIoLINJd5Ei1C4cpcAIT3pQtD0ZYmb98",
        "P": "https://media.licdn.com/dms/image/D5603AQHkUvL0yIjeMQ/profile-displayphoto-shrink_400_400/0/1690610996503?e=1716422400&v=beta&t=_qri5lB_rbdxWKkhmBFY15uJfaPdRfLlj643vUeddZw",
        "Q": "https://media.licdn.com/dms/image/D4D35AQFxzBDdeex6iA/profile-framedphoto-shrink_400_400/0/1690345194603?e=1711717200&v=beta&t=gwmnfc5F8WjywvpcZOYAzqezMVq8gtAn2CN-V3G4Pgs",
        "R": "https://media.licdn.com/dms/image/D4D35AQGDIzw635ii5g/profile-framedphoto-shrink_400_400/0/1673147093442?e=1711717200&v=beta&t=df1K4dVT1OWvIKDKSSR15WTwnTmjHUsPyK7s_nuga48",
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 9,
        "A": 8,
        "B": "PICTURA-Bring imagination to life",
        "C": "Tanvi Kate",
        "D": "Yash pandey",
        "E": "Gargi Khachane",
        "F": "Saransh Badlani",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": "Our project focuses on the creation of a poem-to-image generator, utilising a stable diffusion model refined through the DreamBooth framework. This system takes a poem as input and produces a collection of relevant illustration art images. The primary aim is to bridge the gap between poetry and visual art, providing a streamlined method for generating illustrations that resonate with the themes and emotions encapsulated within the poetry.",
        "J": "https://github.com/Tanvikate/pictura-poem-to-image-generator",
        "K": "https://www.youtube.com/embed/NmZ5BqucmvY?si=azZ2Xt2Ita43eNt2",
        "L": "Deep Learning",
        "M": "https://docs.google.com/presentation/d/1U-kM0SW8E0UCxr_YHtvbGBsfWHA665jtr6rlf6kYc-Y/edit?usp=sharing",
        "N": null,
        "O": "Tanvi Kate",
        "P": "https://media.licdn.com/dms/image/D4D03AQGIQZL0W44uOw/profile-displayphoto-shrink_400_400/0/1702146568355?e=1716422400&v=beta&t=m7JRdehXFqRvAzO1S2XmA8yKCiQd-0DNSLNrzsMJdtQ",
        "Q": "https://media.licdn.com/dms/image/D4E03AQGw1vW-gxN1rg/profile-displayphoto-shrink_200_200/0/1711118825640?e=1716422400&v=beta&t=9HLflIhZGlOtYfWg6rKwZ8CMaIysGMsBlZSYThgnXNI",
        "R": "Saransh Badlani",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 10,
        "A": 9,
        "B": "Health Sync-AI Health news App",
        "C": "Shruti Devlekar",
        "D": "Om Gaydhane",
        "E": "Janhavi Khanvilkar",
        "F": "Kshitij Shidore",
        "G": "Amit Singh",
        "H": "Akansha P",
        "I": null,
        "J": "https://github.com/omgaydhane/IntentNet",
        "K": "https://www.youtube.com/embed/W8y3pdMlnpA?si=Q1IlruwBUPshziOl",
        "L": "NLP",
        "M": "https://docs.google.com/document/d/1xOMdqQ3m7NCMJ3mjDUOOdPIcYLyxOvAddufBG1IJWXU/edit?usp=sharing",
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQE79TIPOOXggw/profile-displayphoto-shrink_400_400/0/1711120579203?e=1716422400&v=beta&t=_AvQJZkZW4sQyBhtNexoK8WkxvPL2oQ9hyLF0zjGH1w",
        "P": "https://media.licdn.com/dms/image/C4D03AQEBaU8-JjK7nw/profile-displayphoto-shrink_400_400/0/1657261006506?e=2147483647&v=beta&t=ah37uknmnZSBadnYLKscOWu5graOewZer87P6VUyf4g",
        "Q": "https://media.licdn.com/dms/image/D4D35AQEu_LfXD51J7Q/profile-framedphoto-shrink_400_400/0/1711116094407?e=1711724400&v=beta&t=dSQj1D886RBzOG9pgwrd9Cd9VCurLc-4-wcQkRr4CgY",
        "R": "Kshitij Shidore",
        "S": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
        "T": "Akansha P"
    },
    {
        "__EMPTY": 11,
        "A": 10,
        "B": "Pharmaceutical Supply Chain Management",
        "C": "Abhishek Thorat",
        "D": "Arnav Singhal",
        "E": "Manvi Gour",
        "F": "Jayesh Agrawal",
        "G": "Ajinkya W",
        "H": "Kusum K",
        "I": null,
        "J": null,
        "K": null,
        "L": "Supply Chain",
        "M": null,
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQEa8B82oxFknQ/profile-displayphoto-shrink_400_400/0/1693289265304?e=1716422400&v=beta&t=afuO9xVO6TcDpmlDn80UiUKTG8vXRW4fEiMYJCy4qu0",
        "P": "Arnav Singhal",
        "Q": "https://media.licdn.com/dms/image/D4D03AQGz2cxAZwdIHw/profile-displayphoto-shrink_400_400/0/1687445720620?e=1716422400&v=beta&t=GzUOqaPPrNhp_99i3MUZX_YX42ebqxV2z_k6NQGe_MY",
        "R": "Jayesh Agrawal",
        "S": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
        "T": "Kusum K"
    },
    {
        "__EMPTY": 12,
        "A": 11,
        "B": "Generating 3D models from 2D images",
        "C": "Sahil Parab",
        "D": "Akshiti K.",
        "E": "Surabhi Tambe",
        "F": null,
        "G": "Dr. Vijayalaxmi",
        "H": "Mamata C",
        "I": "The aim of this project is to develop a deep learning-based approach that can generate detailed and accurate 3D models from single 2D images, thereby simplifying the modeling process and making it accessible to a wider audience.The aim of this project is to develop a deep learning-based approach that can generate detailed and accurate 3D models from single 2D images, thereby simplifying the modeling process and making it accessible to a wider audience.",
        "J": "https://github.com/Surabeee/Generating-3d-model-from-2d-images",
        "K": "https://www.youtube.com/embed/LL1G_42-JP4?si=WCyziS5-0953vTDp",
        "L": "Deep Learning",
        "M": "https://docs.google.com/document/d/1p-qbCAgmy8_YFibvVJ-XZZX4uns0HWlI/edit?usp=sharing&ouid=102765892003751415701&rtpof=true&sd=true",
        "N": null,
        "O": "Sahil Parab",
        "P": "https://media.licdn.com/dms/image/D4D03AQG1t6M2lOifuA/profile-displayphoto-shrink_400_400/0/1709918498079?e=1716422400&v=beta&t=oMckA8ye7T1ML5arNfPBnKQzSphR38MjxS7cDpQHx2k",
        "Q": "Surabhi Tambe",
        "R": null,
        "S": null,
        "T": "Mamata C"
    },
    {
        "__EMPTY": 13,
        "A": 12,
        "B": "Poshan Sankalp",
        "C": "Surya Ganiga",
        "D": "Nimisha Jain",
        "E": "Rohan Singh",
        "F": null,
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": null,
        "J": "https://github.com/satts27/MajorProject",
        "K": "https://drive.google.com/file/d/10reDO6OMIoPKTI7ewkBCst8pHVzRz_cS/view?usp=sharing",
        "L": "Predictive maintenance",
        "M": null,
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQFRFB_XWhumcw/profile-displayphoto-shrink_800_800/0/1690727384759?e=1716422400&v=beta&t=X83c3KOG6ZDIlhGIpPT-CdvjBzUGryn-bF7YpWYEnBQ",
        "P": "https://media.licdn.com/dms/image/D4D03AQGcJm41Flthlw/profile-displayphoto-shrink_800_800/0/1688350383669?e=1716422400&v=beta&t=x6daqnyCAVv4lT1uahaH5BbnAxfFZkVi7VNR03EyQcI",
        "Q": "https://media.licdn.com/dms/image/C4D03AQGhdMNK7z3hzw/profile-displayphoto-shrink_200_200/0/1663418927746?e=2147483647&v=beta&t=gnroc__ub3_LuLAVYP944-LL9b8FRyRbEQ2MjZtOrBo",
        "R": null,
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 14,
        "A": 13,
        "B": "Vahan Suraksha Netra",
        "C": "Naresh Shewkani",
        "D": "Himanshu Sharma",
        "E": "Avanish Srivastava",
        "F": "Shambhu Patil",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": "explores the integration of computer vision in transportation systems, focusing on three key\nareas: Helmet Detection with License Plate Recognition, Vehicle Speed Detection with License Plate Detection, and Automatic\nTraffic Red-Light Violation Detection.The primary goal of the “Vahan Suraksha Netra” project is to develop an integrated system for enhancing road safety by leveraging machine vision technology to monitor and analyze in and out vehicular behavior in real-time. The Project focuses on creating the following features to cover a major chunk of Road Safety actions:\n\n1. Develop an in-car camera system to detect driver drowsiness and emotions, reducing accidents due to driver-related issues.\n2. Develop a rule violation detection system to improve traffic law enforcement and road safety detecting incidents like over speeding and vehicles stopping on busy roads.\n3. Develop a rule violation detection system for: Helmet Detection with License Plate Recognition.\n4. Develop a rule violation detection system for: Vehicle Speed Detection with License Plate Recognition.\n5. Develop a rule violation system for: Traffic Red-light violation detection.\n\nTogether, these modules harness the power of machine learning and computer vision to process complex data in real-time, creating a seamless, safer, and more efficient driving experience.\n\nWorking of Modules:\n1) In the workflow for Driver Drowsiness and Emotion Detection, a camera inside the vehicle captures the driver&#39;s face, utilizing Haar Cascade for facial detection. Emotion analysis discerns the driver&#39;s emotional state, while blink and distraction monitoring tracks eye movements and head gestures to identify signs of drowsiness or distraction. The Neural Network architecture for Drowsiness/Emotion Detection is a complex network designed to analyze facial expressions, eye movements, and other relevant features from camera input. It comprises multiple layers of interconnected nodes that process and extract meaningful patterns to identify driver drowsiness and emotional states.\n\n2)The system integrates machine vision algorithms to detect instances of individuals riding motorcycles or bicycles without wearing helmets. Utilizing object detection techniques, the system identifies and localizes helmets in the captured video frames. Concurrently, license plate recognition algorithms are employed to extract license plate numbers from vehicles within the frame. By combining these capabilities, the system ensures comprehensive enforcement of helmet usage regulations while simultaneously recording license plate information for further law enforcement actions.\n\n3)The system employs machine vision technology to detect vehicles exceeding predefined speed limits, contributing to enhanced road safety measures. Utilizing techniques such as optical character recognition (OCR), the system recognizes license plates of vehicles captured by surveillance cameras. Simultaneously, speed detection algorithms analyze vehicle movement patterns and calculate vehicle speeds based on time and distance measurements. By correlating vehicle speeds with license plate information, the system enables precise identification and enforcement of speed limit violations, promoting safer driving practices.\n\n4)Leveraging advanced computer vision algorithms, the system detects instances of vehicles infringing red traffic signals, thereby enhancing traffic law enforcement and road safety. By analyzing video streams from intersection cameras, the system identifies traffic lights and monitors vehicle behavior in relation to signal changes. Vehicle detection algorithms ascertain the presence of vehicles approaching intersections during red light intervals. Coupled with license plate recognition capabilities, the system records violators&#39; license plate information, facilitating subsequent enforcement actions and promoting adherence to traffic regulations.\n\nThese innovative modules, powered by machine learning and computer vision, collectively contribute to the overarching goal of the “Vahan Suraksha Netra” project: enhancing road safety through proactive monitoring, real-time analysis, and effective enforcement of traffic regulations.",
        "J": "https://github.com/nareshshewkani/Vahan-Suraksha-Netra/tree/master",
        "K": null,
        "L": "Deep Learning",
        "M": "https://docs.google.com/document/d/1_60TMxbbBn5xrK5nuZqXaOBp35PfEYo07rehA3rAmng/edit",
        "N": null,
        "O": "Naresh Shewkani",
        "P": "Himanshu Sharma",
        "Q": "Avanish Srivastava",
        "R": "Shambhu Patil",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 15,
        "A": 14,
        "B": "AI Assistant for youtube & NPTEL courses",
        "C": "Nikita Jethani",
        "D": "Madhusudana Naidu",
        "E": "Manav Pahilwani",
        "F": "Shreya Singh",
        "G": "Ajinkya W",
        "H": "Kusum K",
        "I": "This project develops an AI assistant for YouTube lectures and NPTEL videos, offering video summarization and question generation. Learners access concise summaries and engage in interactive Q&A sessions for deeper understanding. Integration with YouTube and creation of chrome extension ensures seamless access to doubt solving on educational videos. User feedback refines summaries and question generation. The aim is to enhance learning experiences, promote critical thinking, and provide accessible tools for active learning from online educational resources.",
        "J": "https://github.com/E0NIA/AI-Assistant-for-Youtube-Videos",
        "K": null,
        "L": "NLP",
        "M": "https://docs.google.com/document/d/10KOS_BPBuEwfFp4ao0nyssYsbC8_Ss6cx2aBG4eh6xk/edit?usp=sharing",
        "N": null,
        "O": "Nikita Jethani",
        "P": "Madhusudana Naidu",
        "Q": "Manav Pahilwani",
        "R": "Shreya Singh",
        "S": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
        "T": "Kusum K"
    },
    {
        "__EMPTY": 16,
        "A": 15,
        "B": "Predictive maintenance of servers",
        "C": "Harshita Anala",
        "D": "Mahindra Chetwani",
        "E": "Manas Lalwani",
        "F": "Parth Suryavanshi",
        "G": "Dr. Anjali Yeole",
        "H": "Himanshi G",
        "I": "Our proposal involves creating a web application that utilises machine sensor data to forecast the likelihood of machine downtime based on the historical data of its servers components . This is going to be carried out by\n1. Carry out data cleaning on the data set that includes records of various parameters gathered by the server&#39;s sensors, and look for correlations to find patterns related to the server&#39;s downtime.\n2. Determine and train the best machine learning model that can predict system failure well in advance using the live data supplied to the corresponding model after analysing the data set and determining the correlation.\n3. In terms of operations, the model will be highly helpful to the person operating the machine, as well as to their individual managers and other stakeholders. The project is expected to yield highly efficient results while also saving a significant amount of time. Profit and productivity as a whole have increased as a result.",
        "J": null,
        "K": null,
        "L": "Predictive maintenance",
        "M": "https://docs.google.com/document/d/12lpMdo29V86HU1lmmGi7EkL6hY55gu-xRR21Spa_JFE/edit?usp=sharing",
        "N": null,
        "O": "https://media.licdn.com/dms/image/C4E03AQFQex41pJ44fw/profile-displayphoto-shrink_800_800/0/1640583867524?e=1716422400&v=beta&t=1YPUy0gxlFgBQq5XaPuPcoCXryndivOKFKRb0HOVhWE",
        "P": "Mahindra Chetwani",
        "Q": "Manas Lalwani",
        "R": "https://media.licdn.com/dms/image/C4D03AQFnB7mzaYm0Kg/profile-displayphoto-shrink_400_400/0/1660965995238?e=1716422400&v=beta&t=_12sWqix8OsLNL_ndqk8IUBsfkm0OtffRDImbJGOsWI",
        "S": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
        "T": "Himanshi G"
    },
    {
        "__EMPTY": 17,
        "A": 16,
        "B": "Demysification of neural network through explainable AI",
        "C": "Priyanshu Singh",
        "D": "Sneha Kadambala",
        "E": "Shreyas Satre",
        "F": "Atharva khangar",
        "G": "Sangeeta Oswal",
        "H": "Bhavana C",
        "I": "Project Title: Demystification of Neural Networks through Explainable AI\n\nIntroduction:\nIn recent years, neural networks have demonstrated remarkable capabilities in various fields, ranging from image recognition to natural language processing. However, the complexity and \"black-box\" nature of neural networks often pose challenges in understanding their decision-making processes, hindering their widespread adoption in critical applications. To address this challenge, our project aims to demystify neural networks using Explainable Artificial Intelligence (XAI) techniques.\n\nProject Description:\n\nOur project focuses on creating a transparent understanding of neural networks by leveraging a combination of techniques, including autoencoder architectures, Temporal Convolutional Networks (TCN) for time-series data analysis, SHAP (SHapley Additive exPlanations) for model interpretation, and Natural Language Processing (NLP) for intuitive explanation generation.\n\n1. Autoencoder Setup with TCN:\n\nWe begin by constructing an autoencoder architecture tailored for the specific task of analyzing time-series data with 51 feature attributes. Autoencoders are neural networks trained to reconstruct input data, thus learning a compressed representation of the input. We integrate Temporal Convolutional Networks (TCN) within the autoencoder setup to effectively capture temporal dependencies in the time-series data. TCNs are renowned for their ability to model long-range dependencies efficiently, making them suitable for processing sequential data.\n\n2. SHAP Analysis:\n\nOnce the autoencoder with TCN is trained on the dataset, we employ (SHapley Additive exPlanations) SHAP values to understand the importance of each feature attribute in the model&#39;s decision-making process. SHAP provides a coherent explanation of individual predictions by quantifying the impact of each feature on the model&#39;s output. By visualizing SHAP values, users gain insights into how different features influence the neural network&#39;s decisions, enhancing transparency and interpretability.\n\n3. NLP-Based Explanation Generation:\n\nTo further enhance the interpretability of the neural network&#39;s decisions, we leverage Natural Language Processing (NLP) techniques to generate human-readable explanations. By analyzing the learned representations and SHAP values, we extract key insights and transform them into intuitive explanations in natural language. These explanations provide users with actionable insights into the model&#39;s behavior, enabling informed decision-making.\n\nExpected Outcome:\n\nThrough our project, we aim to achieve the following outcomes:\n\nEnhanced Understanding: Provide users with a clear understanding of how neural networks operate, particularly in the context of time-series data analysis with multiple features.\nTransparency: Offer transparent insights into the decision-making process of the neural network, facilitating trust and confidence in its predictions.\nAccessibility: Make complex neural network models accessible to a wider audience by presenting explanations in a comprehensible and intuitive manner.\nPractical Utility: Enable stakeholders to make informed decisions based on the insights gleaned from the explainable AI techniques employed in the project.",
        "J": "https://github.com/Shreyassatre/BE-Project-grp-16.git",
        "K": "https://www.youtube.com/embed/8tw4_AsgXeI?si=krtdLmiIRvTncPxV",
        "L": "Deep Learning",
        "M": null,
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQE0jbpf4vjKGA/profile-displayphoto-shrink_400_400/0/1710834423093?e=1716422400&v=beta&t=35XRoz31tP2TJd083sMd2d7s3lxulDh2qX-wSraeTUI",
        "P": "https://media.licdn.com/dms/image/D5603AQFw5k90oNBbsg/profile-displayphoto-shrink_400_400/0/1710804707136?e=1716422400&v=beta&t=hJtgjoyJa5emTQ-aHC9ccutltUpoZriOtrjOx2rFfNw",
        "Q": "https://media.licdn.com/dms/image/D4D03AQG1pJI8QHSuPA/profile-displayphoto-shrink_400_400/0/1701791736260?e=1716422400&v=beta&t=5nshYwBT-hiL945CGNyrNu0X4lybqE1ixz3J3WsHbF8",
        "R": "https://drive.google.com/file/d/15-iqEpgNd5YqMghaz8Jprh3ktdbg7mcx/view?usp=drive_link",
        "S": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
        "T": "Bhavana C"
    },
    {
        "__EMPTY": 18,
        "A": 17,
        "B": "Aspect Base senitiment Analysis",
        "C": "Omkar Korade",
        "D": "Muhammad Faayez",
        "E": "Harsh Rohra",
        "F": "Govind Tiwari",
        "G": "Amit Singh",
        "H": "Akansha P",
        "I": "An ML model that compares a student answer and a model answer and gives the accuracy of how similar both annswers are. This can be used by teachers and by anyone who wants to automate the task of grading tests with descriptive answers. The user needs to input both the model answer and student answer either by typing them out or uploading their images. If images are uploaded the model will utilise the OCR functionality to extract the text from them and proceed ahead.",
        "J": "https://github.com/omkarkorde27/MajorProject",
        "K": null,
        "L": "NLP",
        "M": "https://drive.google.com/file/d/1-39psvh70D87A_p35OU5nX1kd1nY8H8j/view?usp=sharing",
        "N": null,
        "O": "https://media.licdn.com/dms/image/D4D03AQEIa1lSbjc25w/profile-displayphoto-shrink_800_800/0/1704370334344?e=1716422400&v=beta&t=WIyAszqK6bdqdAO_-MfFTptca3khYGaOLdYylNfXX0A",
        "P": "Muhammad Faayez",
        "Q": "https://media.licdn.com/dms/image/D4D03AQHDmU5TEH81dg/profile-displayphoto-shrink_400_400/0/1711119706707?e=1716422400&v=beta&t=H0DvQLsTInd-4NTizIpg9b-eo0s-zLHHhKCGA2b2vJs",
        "R": "https://media.licdn.com/dms/image/C4D03AQHXejxrYN3J_g/profile-displayphoto-shrink_400_400/0/1661512805935?e=1716422400&v=beta&t=o7ZodhYnAczJbVQnBdGNR3YH-t8SdIqyKVwS6Efk_lo",
        "S": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
        "T": "Akansha P"
    }
]