{
    "2023-24": [
        {
            "grpno": 1,
            "title": "Detecting cyberbullying using Deep learning",
            "member1": "Prasad Jawale",
            "member2": "Anushka Kulkarni",
            "member3": "Subrato Tapaswi",
            "member4": "Lakshman Bhojwani",
            "guide": "Dr. Vijayalaxmi",
            "coguide": "Mamata C",
            "description": "The project, titled \"Detecting Cyberbullying using Deep Learning,\" aims to investigate cyber aggression on Twitter, focusing on identifying derogatory tweets based on gender, race, or sexual orientation. It seeks to develop an automated system capable of accurately analyzing text-based content across online platforms to detect instances of cyberbullying. \r\n\r\nLeveraging a dataset of approximately 110,000 instances, the study explores various detection methods, including non-deep learning approaches such as SVM, L2 regularization, and random forest, as well as deep learning techniques utilizing BERT. Additionally, an ensemble learning approach combining BERT and LSTM is planned. \r\n\r\nThe classification system categorizes tweets into six major categories: gender, age, religion, not cyberbullying, and ethnicity. To evaluate the effectiveness of these methods, a test dataset of 20,000 tweets will be employed, facilitating a comparative analysis to determine which model best identifies and classifies cyberbullying tweets accurately.",
            "github": "https://github.com/Tydos/Cyberbullying-Detection/tree/main",
            "demo": "https://www.youtube.com/embed/tp65dH-YIBg?si=817PgYnh9bNJm9dS",
            "domain": "Deep Learning",
            "Research Paper Doc": "https://docs.google.com/document/d/1K4-byLQrLmqAYYjZs4Te-WuVD1xgoqW7/edit",
            "Fundings Received": true,
            "member1 photo": "https://media.licdn.com/dms/image/C4D03AQEo4bsvzTnLiQ/profile-displayphoto-shrink_400_400/0/1662101524731?e=1716422400&v=beta&t=nVWBD-j6jzxRMqoi68-IqvyTYOUY362evosUvlefRiU",
            "member2 photo": "https://media.licdn.com/dms/image/D4D03AQFpnIgP_yWpMQ/profile-displayphoto-shrink_400_400/0/1661488412068?e=1716422400&v=beta&t=Xo523AtSgqlrbnaM42BJRn-VOUSILAdSgaUp4kIe6kg",
            "member3 photo": "https://media.licdn.com/dms/image/C5603AQF2xxD2ZwXU-A/profile-displayphoto-shrink_200_200/0/1643320265523?e=2147483647&v=beta&t=Zglhi9Frgcq2MVhxV86XQIAHDOnp33keLNFNW3-uLMk",
            "member4 photo": "Lakshman Bhojwani",
            "coguide photo": "Mamata C",
            "guide photo": null
        },
        {
            "grpno": 2,
            "title": "SecurGAN",
            "member1": "Arunim Chakraborty",
            "member2": "Satyam Dubey",
            "member3": "Prathmesh Pawar",
            "member4": "Yash Sarang",
            "guide": "Dr. Anjali Yeole",
            "coguide": "Himanshi G",
            "description": "The project, titled \"SecurGAN: AI-Powered Facial Inpainting for Enhanced Law Enforcement and Security,\" aims to develop a system utilizing AI-powered facial inpainting techniques with Generative Adversarial Neural Networks (GANs). This system reconstructs the facial features of an unknown person who has covered their face, generating an accurate representation based on visible features and contextual information in the image. Its goal is to provide law enforcement agencies with a tool that assists in identifying individuals involved in criminal activities or other security-related incidents where their faces are obscured, enhancing the capabilities of law enforcement personnel in gathering information and solving cases effectively through advanced machine learning algorithms.",
            "github": "https://github.com/prathmeshppawar/Major-Project",
            "demo": "https://www.youtube.com/embed/55NLy-MzmM4?si=QmWXQ2xAkelkCsBc",
            "domain": "Computer Vision",
            "Research Paper Doc": "https://drive.google.com/file/d/1mO4MC2TRHs4Alb9EvCbCvigf42h3LNOB/view?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/C5603AQFJQhH7sl6MYw/profile-displayphoto-shrink_400_400/0/1652889170591?e=1716422400&v=beta&t=JqV4RTC_9pfH-9kf9kmC2Yn3jUnrJOV4QFvGv3IIlqQ",
            "member2 photo": "https://media.licdn.com/dms/image/C5603AQEpe0uEcU0nug/profile-displayphoto-shrink_800_800/0/1657954640571?e=1716422400&v=beta&t=gn5O2JDPGFXvK97LuCOxQbvStJyOdAOXf3citJTWsDk",
            "member3 photo": "https://media.licdn.com/dms/image/C4D03AQHJi3HY2BphPw/profile-displayphoto-shrink_400_400/0/1662209363149?e=1716422400&v=beta&t=tVTvuQCRVcmv1kFTLjDb4iR3Vyb8eDMyJb1wvesfDio",
            "member4 photo": "https://media.licdn.com/dms/image/C4D03AQF0ykYJLs_Xxg/profile-displayphoto-shrink_400_400/0/1652212779374?e=1716422400&v=beta&t=nyjncyqx9gdwRgKWnx1-eH6XqfbJNn70jujcqHIn7sM",
            "coguide photo": "Himanshi G",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg"
        },
        {
            "grpno": 3,
            "title": "Location Predictor",
            "member1": "Akanksha Singh",
            "member2": "Ashish Gupta",
            "member3": "Abhijay Sharangdhar",
            "member4": "Hrishikesh Kudale",
            "guide": "Sangeeta Oswal",
            "coguide": "Bhavana C",
            "description": "In Mumbai's lively coffee culture, selecting a new cafe location like AbCoffee is critical but challenging. Traditional methods of site selection can be risky. Our project uses data-driven spatial analysis techniques to pinpoint optimal expansion locations.\r\n\r\nWe employ clustering analysis, specifically the DBSCAN algorithm, to uncover cafe clusters based on proximity. This helps us understand distribution patterns and success factors like density and proximity to transportation hubs. We also analyze broader market dynamics such as real estate pricing and transportation accessibility. Integrating property price data and transportation proximity provides insights into the market landscape. Our approach is scalable and adaptable beyond Mumbai, making it applicable to other cities with minimal adjustments. This flexibility allows businesses to replicate our insights in different market environments. Our recommendations provide actionable insights for businesses like AbCoffee, highlighting potential high-yield locations with less competition. This data-driven approach minimizes risks and maximizes success in competitive markets.\r\n\r\nIn summary, our project leverages data science to guide strategic coffee shop expansion decisions, empowering businesses to thrive in dynamic urban environments.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
            "github": "https://github.com/akanksha2828/Major-Project/blob/master/abcoffee_prediction.ipynb",
            "demo": "https://www.youtube.com/embed/8bYeRJHqj4o?si=NBm4D4NArcNTgWjc",
            "domain": null,
            "Research Paper Doc": "https://docs.google.com/document/d/1EiXdgmJC_ZDCdTDf1oOkoY48fN_wcEdk9I5ddA2MuD0/edit?usp=drivesdk",
            "Fundings Received": false,
            "member1 photo": "Akanksha Singh",
            "member2 photo": "Ashish Gupta",
            "member3 photo": "https://media.licdn.com/dms/image/D4D03AQGvPD8GyBUbug/profile-displayphoto-shrink_800_800/0/1681057643897?e=1716422400&v=beta&t=8CY90HB476aLpkJtczKUmcwBhVlnWZc7HeMWKc-hkBU",
            "member4 photo": "Hrishikesh Kudale",
            "coguide photo": "Bhavana C",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg"
        },
        {
            "grpno": 4,
            "title": "Language Text Summarisation",
            "member1": "Siddhant Dongre",
            "member2": "Shubham Hadawle",
            "member3": "Pranav Kotkar",
            "member4": "Om Bhatia",
            "guide": "Amit Singh",
            "coguide": "Akansha P",
            "description": "When it comes to extracting pertinent information from lengthy textual materials, text summary is essential. Nonetheless, there are very few language models available for use with texts written in regional or native tongues. Regional languages frequently face issues such as a lack of digital material, resource constraints, linguistic inflections, and structural variance. This work attempts to fill up those similar gaps so that we can model text summarizers in regional languages. In this work, we investigate the efficacy of self-attention mechanisms for abstractive text summarization in two Indo-Aryan languages, Gujarati and Hindi, by particularly utilizing a Conventional Transformer. Our methodology entails using the ILSUM dataset to train a specially constructed Transformer model. Articles, headlines, and summaries are used to curate corpora for the Indian Language Summarization project (ILSUM).",
            "github": "https://github.com/shubham-hadawle/Text-Summarization-for-Indo-Aryan-Languages-using-Self-Attention-Mechanism",
            "demo": "https://drive.google.com/file/d/15_TY20xqhdA_Mgdqx8G4jSZC1yqNbCUL/view?usp=sharing",
            "domain": "NLP",
            "Research Paper Doc": null,
            "Fundings Received": false,
            "member1 photo": "Siddhant Dongre",
            "member2 photo": "https://media.licdn.com/dms/image/C5603AQERpRlZZoxhvg/profile-displayphoto-shrink_400_400/0/1642254667781?e=1716422400&v=beta&t=cixTN9AsVGP2UZsPw3jE2Dk86cSAlZTlVzad-9qlZ6o",
            "member3 photo": "https://media.licdn.com/dms/image/D4D03AQG-KSd4kEJbMQ/profile-displayphoto-shrink_400_400/0/1688983708371?e=1716422400&v=beta&t=ftg1rX8ZqRctthOmDuyHk_plP50SfeTsfFR-EPB4Q_Y",
            "member4 photo": "Om Bhatia",
            "coguide photo": "Akansha P",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg"
        },
        {
            "grpno": 5,
            "title": "AI Based smart meter",
            "member1": "Sarthak Bansod",
            "member2": "Sheryl Bellary",
            "member3": "Sheetal Dixit",
            "member4": "Soham Jadiye",
            "guide": "Ajinkya W",
            "coguide": "Kusum K",
            "description": "The AI-based smart meter project aims to monitor electricity consumption, humidity, and CO2 levels within a room using IoT devices. Data collected from these devices is then displayed on both a website and a mobile application for user accessibility. Additionally, machine learning techniques, such as ARIMA,LSTM,RNN are employed to forecast future electricity consumption patterns. This integration of IoT and machine learning enables users to optimize energy usage and make informed decisions about electricity consumption.",
            "github": "https://github.com/SohamJadiye/AI-Based-Smart-Meter",
            "demo": null,
            "domain": "Deep Learning",
            "Research Paper Doc": "https://drive.google.com/file/d/1v1G_-t19GgEu3ocn3sm2dtX2UIQWeNUf/view?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "Sarthak Bansod",
            "member2 photo": "Sheryl Bellary",
            "member3 photo": "Sheetal Dixit",
            "member4 photo": "https://media.licdn.com/dms/image/D4D03AQFcjBoXI7k7kA/profile-displayphoto-shrink_400_400/0/1695790820929?e=1716422400&v=beta&t=Pm-1KNJz0-4Xdp5-APGcQb-OEOoUIDupb_OiMtvIotc",
            "coguide photo": "Kusum K",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg"
        },
        {
            "grpno": 6,
            "title": "Visual Speech Recognition using AI",
            "member1": "Tejas Patne",
            "member2": "Arya Kurup",
            "member3": "Rupesh Dhirwani",
            "member4": "Akshat Tiwari",
            "guide": "Dr. Vijayalaxmi",
            "coguide": "Mamata C",
            "description": "Visual speech recognition using deep learning involves the utilization of neural network architectures to predict speech content solely based on visual cues extracted from videos of speakers. This technology holds significant potential for various applications, including improving speech recognition accuracy in noisy environments, aiding individuals with hearing impairments, enhancing human-computer interaction in multimedia systems, and facilitating automatic transcription of videos. The first step involves preprocessing the video data to extract relevant visual features. This typically involves techniques such as face detection and tracking, lip region segmentation, and feature extraction. Common features include lip movements, facial expressions, and head gestures. LipNet is a deep learning architecture specifically designed for lip reading. It combines convolutional neural networks (CNNs) for feature extraction from lip images with recurrent neural networks (RNNs) such as Long Short-Term Memory (LSTM) networks for sequence modeling and prediction.STCNNs are specialized architectures designed to capture both spatial and temporal information from video data. They typically consist of 3D convolutional layers followed by fully connected layers for classification or prediction tasks. Bi-LSTMs are recurrent neural networks that process input sequences in both forward and backward directions, enabling them to capture temporal dependencies effectively. They are often used for sequence modeling tasks such as speech recognition and natural languageprocessing. Once the architecture is selected, the model is trained using labeled video data, where the input consists of visual features extracted from video frames, and the output is the corresponding speech content. The training process involves optimizing the model parameters to minimize prediction errors using techniques like stochastic gradient descent (SGD) or adaptive optimization algorithms like Adam. After training, the model is evaluated on a separate test set to assess its performance. Common evaluation metrics include accuracy, precision, recall, and F1 score. Additionally, qualitative assessment through visual inspection of predictions can provide insights into the model's strengths and weaknesses. Once the model is trained and evaluated satisfactorily, it can be deployed for real-world applications. These applications may include real-time speech recognition in videos, automatic transcription of spoken content, enhancing accessibility for individuals with hearing impairments, and integrating with multimedia systems for interactive experiences. Overall, visual speech recognition using deep learning holds promise for advancing the state-of-the-art in speech processing and multimedia technology, with potential benefits across various domains.\n",
            "github": "https://github.com/TejasPatne/visual-speech-recognition/tree/main",
            "demo": "https://www.youtube.com/embed/hAyl4jf-3bo?si=zA6kazz8lPe0ZONg",
            "domain": "Deep Learning",
            "Research Paper Doc": "https://docs.google.com/document/d/1S_HG9tPAJ6JyKPIsGSs27Trmb5kxH2qBpl5t7Ejcbyk/edit?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/D4D03AQGhRusuZJ8hLQ/profile-displayphoto-shrink_200_200/0/1675172921760?e=2147483647&v=beta&t=6Tp6UPcjCsLP1Lj0P1EyCO1RRsVhXIldXIo4C24l3ME",
            "member2 photo": "https://media.licdn.com/dms/image/D4D03AQEql3wgymmxGQ/profile-displayphoto-shrink_400_400/0/1711118147801?e=1716422400&v=beta&t=q4-oZ9KFPpYb0M2N4ij5sK17Efpdv6Yyf4_FhqVaHTE",
            "member3 photo": "https://media.licdn.com/dms/image/D4D03AQExokynmRzyJQ/profile-displayphoto-shrink_400_400/0/1711130756589?e=1716422400&v=beta&t=xRjzQLqiKEN6FhHVJfSt2JW9Ef6vwl4oZeSeQ5JjnWU",
            "member4 photo": "https://media.licdn.com/dms/image/D4D35AQHEncAi_NxImw/profile-framedphoto-shrink_400_400/0/1663438705871?e=1711760400&v=beta&t=oDKFOAXIPlqurQhnx2IqCxNMAjdVngDjVEIc2LkHFt0",
            "coguide photo": "Mamata C",
            "guide photo": null
        },
        {
            "grpno": 7,
            "title": "Maatri Shakthi",
            "member1": "Vemburaj Konar",
            "member2": "Mayur Pimpude",
            "member3": "Heramb Pawar",
            "member4": "Deepak Prasad",
            "guide": "Dr. Anjali Yeole",
            "coguide": "Himanshi G",
            "description": "The objective is to leverage machine learning and Deep Learning to accurately assess the malnutrition vulnerability of infants using demographic and socio-economic attributes from the census data. \nThe creation of a user-friendly dashboard will allow healthcare practitioners and policymakers to efficiently interpret and explore the prediction outcomes, facilitating targeted interventions and evidence-based decision-making to address malnutrition and its associated challenges among newborn\n",
            "github": "https://github.com/MayurPimpude/BE-Project",
            "demo": "https://www.youtube.com/embed/xdJ_f735Ft8?si=cMA9YvJsFa1gH-rL",
            "domain": "Deep Learning",
            "Research Paper Doc": "https://docs.google.com/document/d/1gzMElYVN55oS-qHLVD7zLVYQFby8BTOn2urxl3YJRT4/edit?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/D4D03AQHpbb7DZ0teyw/profile-displayphoto-shrink_400_400/0/1693139740090?e=1716422400&v=beta&t=Vz5dRLjSSAOSIoLINJd5Ei1C4cpcAIT3pQtD0ZYmb98",
            "member2 photo": "https://media.licdn.com/dms/image/D5603AQHkUvL0yIjeMQ/profile-displayphoto-shrink_400_400/0/1690610996503?e=1716422400&v=beta&t=_qri5lB_rbdxWKkhmBFY15uJfaPdRfLlj643vUeddZw",
            "member3 photo": "https://media.licdn.com/dms/image/D4D35AQFxzBDdeex6iA/profile-framedphoto-shrink_400_400/0/1690345194603?e=1711717200&v=beta&t=gwmnfc5F8WjywvpcZOYAzqezMVq8gtAn2CN-V3G4Pgs",
            "member4 photo": "https://media.licdn.com/dms/image/D4D35AQGDIzw635ii5g/profile-framedphoto-shrink_400_400/0/1673147093442?e=1711717200&v=beta&t=df1K4dVT1OWvIKDKSSR15WTwnTmjHUsPyK7s_nuga48",
            "coguide photo": "Himanshi G",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg"
        },
        {
            "grpno": 8,
            "title": "PICTURA-Bring imagination to life",
            "member1": "Tanvi Kate",
            "member2": "Yash pandey",
            "member3": "Gargi Khachane",
            "member4": "Saransh Badlani",
            "guide": "Sangeeta Oswal",
            "coguide": "Bhavana C",
            "description": "Our project focuses on the creation of a poem-to-image generator, utilising a stable diffusion model refined through the DreamBooth framework. This system takes a poem as input and produces a collection of relevant illustration art images. The primary aim is to bridge the gap between poetry and visual art, providing a streamlined method for generating illustrations that resonate with the themes and emotions encapsulated within the poetry.",
            "github": "https://github.com/Tanvikate/pictura-poem-to-image-generator",
            "demo": "https://www.youtube.com/embed/NmZ5BqucmvY?si=azZ2Xt2Ita43eNt2",
            "domain": "Deep Learning",
            "Research Paper Doc": "https://docs.google.com/presentation/d/1U-kM0SW8E0UCxr_YHtvbGBsfWHA665jtr6rlf6kYc-Y/edit?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "Tanvi Kate",
            "member2 photo": "https://media.licdn.com/dms/image/D4D03AQGIQZL0W44uOw/profile-displayphoto-shrink_400_400/0/1702146568355?e=1716422400&v=beta&t=m7JRdehXFqRvAzO1S2XmA8yKCiQd-0DNSLNrzsMJdtQ",
            "member3 photo": "https://media.licdn.com/dms/image/D4E03AQGw1vW-gxN1rg/profile-displayphoto-shrink_200_200/0/1711118825640?e=1716422400&v=beta&t=9HLflIhZGlOtYfWg6rKwZ8CMaIysGMsBlZSYThgnXNI",
            "member4 photo": "Saransh Badlani",
            "coguide photo": "Bhavana C",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg"
        },
        {
            "grpno": 9,
            "title": "Health Sync-AI Health news App",
            "member1": "Shruti Devlekar",
            "member2": "Om Gaydhane",
            "member3": "Janhavi Khanvilkar",
            "member4": "Kshitij Shidore",
            "guide": "Amit Singh",
            "coguide": "Akansha P",
            "description": null,
            "github": "https://github.com/omgaydhane/IntentNet",
            "demo": "https://www.youtube.com/embed/W8y3pdMlnpA?si=Q1IlruwBUPshziOl",
            "domain": "NLP",
            "Research Paper Doc": "https://docs.google.com/document/d/1xOMdqQ3m7NCMJ3mjDUOOdPIcYLyxOvAddufBG1IJWXU/edit?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/D4D03AQE79TIPOOXggw/profile-displayphoto-shrink_400_400/0/1711120579203?e=1716422400&v=beta&t=_AvQJZkZW4sQyBhtNexoK8WkxvPL2oQ9hyLF0zjGH1w",
            "member2 photo": "https://media.licdn.com/dms/image/C4D03AQEBaU8-JjK7nw/profile-displayphoto-shrink_400_400/0/1657261006506?e=2147483647&v=beta&t=ah37uknmnZSBadnYLKscOWu5graOewZer87P6VUyf4g",
            "member3 photo": "https://media.licdn.com/dms/image/D4D35AQEu_LfXD51J7Q/profile-framedphoto-shrink_400_400/0/1711116094407?e=1711724400&v=beta&t=dSQj1D886RBzOG9pgwrd9Cd9VCurLc-4-wcQkRr4CgY",
            "member4 photo": "Kshitij Shidore",
            "coguide photo": "Akansha P",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg"
        },
        {
            "grpno": 10,
            "title": "Pharmaceutical Supply Chain Management",
            "member1": "Abhishek Thorat",
            "member2": "Arnav Singhal",
            "member3": "Manvi Gour",
            "member4": "Jayesh Agrawal",
            "guide": "Ajinkya W",
            "coguide": "Kusum K",
            "description": null,
            "github": null,
            "demo": null,
            "domain": "Supply Chain",
            "Research Paper Doc": null,
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/D4D03AQEa8B82oxFknQ/profile-displayphoto-shrink_400_400/0/1693289265304?e=1716422400&v=beta&t=afuO9xVO6TcDpmlDn80UiUKTG8vXRW4fEiMYJCy4qu0",
            "member2 photo": "Arnav Singhal",
            "member3 photo": "https://media.licdn.com/dms/image/D4D03AQGz2cxAZwdIHw/profile-displayphoto-shrink_400_400/0/1687445720620?e=1716422400&v=beta&t=GzUOqaPPrNhp_99i3MUZX_YX42ebqxV2z_k6NQGe_MY",
            "member4 photo": "Jayesh Agrawal",
            "coguide photo": "Kusum K",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg"
        },
        {
            "grpno": 11,
            "title": "Generating 3D models from 2D images",
            "member1": "Sahil Parab",
            "member2": "Akshiti K.",
            "member3": "Surabhi Tambe",
            "member4": null,
            "guide": "Dr. Vijayalaxmi",
            "coguide": "Mamata C",
            "description": "The aim of this project is to develop a deep learning-based approach that can generate detailed and accurate 3D models from single 2D images, thereby simplifying the modeling process and making it accessible to a wider audience.The aim of this project is to develop a deep learning-based approach that can generate detailed and accurate 3D models from single 2D images, thereby simplifying the modeling process and making it accessible to a wider audience.",
            "github": "https://github.com/Surabeee/Generating-3d-model-from-2d-images",
            "demo": "https://www.youtube.com/embed/LL1G_42-JP4?si=WCyziS5-0953vTDp",
            "domain": "Deep Learning",
            "Research Paper Doc": "https://docs.google.com/document/d/1p-qbCAgmy8_YFibvVJ-XZZX4uns0HWlI/edit?usp=sharing&ouid=102765892003751415701&rtpof=true&sd=true",
            "Fundings Received": false,
            "member1 photo": "Sahil Parab",
            "member2 photo": "https://media.licdn.com/dms/image/D4D03AQG1t6M2lOifuA/profile-displayphoto-shrink_400_400/0/1709918498079?e=1716422400&v=beta&t=oMckA8ye7T1ML5arNfPBnKQzSphR38MjxS7cDpQHx2k",
            "member3 photo": "Surabhi Tambe",
            "member4 photo": null,
            "coguide photo": "Mamata C",
            "guide photo": null
        },
        {
            "grpno": 12,
            "title": "Poshan Sankalp",
            "member1": "Surya Ganiga",
            "member2": "Nimisha Jain",
            "member3": "Rohan Singh",
            "member4": null,
            "guide": "Dr. Anjali Yeole",
            "coguide": "Himanshi G",
            "description": null,
            "github": "https://github.com/satts27/MajorProject",
            "demo": "https://drive.google.com/file/d/10reDO6OMIoPKTI7ewkBCst8pHVzRz_cS/view?usp=sharing",
            "domain": "Predictive maintenance",
            "Research Paper Doc": null,
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/D4D03AQFRFB_XWhumcw/profile-displayphoto-shrink_800_800/0/1690727384759?e=1716422400&v=beta&t=X83c3KOG6ZDIlhGIpPT-CdvjBzUGryn-bF7YpWYEnBQ",
            "member2 photo": "https://media.licdn.com/dms/image/D4D03AQGcJm41Flthlw/profile-displayphoto-shrink_800_800/0/1688350383669?e=1716422400&v=beta&t=x6daqnyCAVv4lT1uahaH5BbnAxfFZkVi7VNR03EyQcI",
            "member3 photo": "https://media.licdn.com/dms/image/C4D03AQGhdMNK7z3hzw/profile-displayphoto-shrink_200_200/0/1663418927746?e=2147483647&v=beta&t=gnroc__ub3_LuLAVYP944-LL9b8FRyRbEQ2MjZtOrBo",
            "member4 photo": null,
            "coguide photo": "Himanshi G",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg"
        },
        {
            "grpno": 13,
            "title": "Vahan Suraksha Netra",
            "member1": "Naresh Shewkani",
            "member2": "Himanshu Sharma",
            "member3": "Avanish Srivastava",
            "member4": "Shambhu Patil",
            "guide": "Sangeeta Oswal",
            "coguide": "Bhavana C",
            "description": "explores the integration of computer vision in transportation systems, focusing on three key\nareas: Helmet Detection with License Plate Recognition, Vehicle Speed Detection with License Plate Detection, and Automatic\nTraffic Red-Light Violation Detection.The primary goal of the “Vahan Suraksha Netra” project is to develop an integrated system for enhancing road safety by leveraging machine vision technology to monitor and analyze in and out vehicular behavior in real-time. The Project focuses on creating the following features to cover a major chunk of Road Safety actions:\r\n\r\n1. Develop an in-car camera system to detect driver drowsiness and emotions, reducing accidents due to driver-related issues.\r\n2. Develop a rule violation detection system to improve traffic law enforcement and road safety detecting incidents like over speeding and vehicles stopping on busy roads.\r\n3. Develop a rule violation detection system for: Helmet Detection with License Plate Recognition.\r\n4. Develop a rule violation detection system for: Vehicle Speed Detection with License Plate Recognition.\r\n5. Develop a rule violation system for: Traffic Red-light violation detection.\r\n\r\nTogether, these modules harness the power of machine learning and computer vision to process complex data in real-time, creating a seamless, safer, and more efficient driving experience.\r\n\r\nWorking of Modules:\r\n1) In the workflow for Driver Drowsiness and Emotion Detection, a camera inside the vehicle captures the driver's face, utilizing Haar Cascade for facial detection. Emotion analysis discerns the driver's emotional state, while blink and distraction monitoring tracks eye movements and head gestures to identify signs of drowsiness or distraction. The Neural Network architecture for Drowsiness/Emotion Detection is a complex network designed to analyze facial expressions, eye movements, and other relevant features from camera input. It comprises multiple layers of interconnected nodes that process and extract meaningful patterns to identify driver drowsiness and emotional states.\r\n\r\n2)The system integrates machine vision algorithms to detect instances of individuals riding motorcycles or bicycles without wearing helmets. Utilizing object detection techniques, the system identifies and localizes helmets in the captured video frames. Concurrently, license plate recognition algorithms are employed to extract license plate numbers from vehicles within the frame. By combining these capabilities, the system ensures comprehensive enforcement of helmet usage regulations while simultaneously recording license plate information for further law enforcement actions.\r\n\r\n3)The system employs machine vision technology to detect vehicles exceeding predefined speed limits, contributing to enhanced road safety measures. Utilizing techniques such as optical character recognition (OCR), the system recognizes license plates of vehicles captured by surveillance cameras. Simultaneously, speed detection algorithms analyze vehicle movement patterns and calculate vehicle speeds based on time and distance measurements. By correlating vehicle speeds with license plate information, the system enables precise identification and enforcement of speed limit violations, promoting safer driving practices.\r\n\r\n4)Leveraging advanced computer vision algorithms, the system detects instances of vehicles infringing red traffic signals, thereby enhancing traffic law enforcement and road safety. By analyzing video streams from intersection cameras, the system identifies traffic lights and monitors vehicle behavior in relation to signal changes. Vehicle detection algorithms ascertain the presence of vehicles approaching intersections during red light intervals. Coupled with license plate recognition capabilities, the system records violators' license plate information, facilitating subsequent enforcement actions and promoting adherence to traffic regulations.\r\n\r\nThese innovative modules, powered by machine learning and computer vision, collectively contribute to the overarching goal of the “Vahan Suraksha Netra” project: enhancing road safety through proactive monitoring, real-time analysis, and effective enforcement of traffic regulations.",
            "github": "https://github.com/nareshshewkani/Vahan-Suraksha-Netra/tree/master",
            "demo": null,
            "domain": "Deep Learning",
            "Research Paper Doc": "https://docs.google.com/document/d/1_60TMxbbBn5xrK5nuZqXaOBp35PfEYo07rehA3rAmng/edit",
            "Fundings Received": false,
            "member1 photo": "Naresh Shewkani",
            "member2 photo": "Himanshu Sharma",
            "member3 photo": "Avanish Srivastava",
            "member4 photo": "Shambhu Patil",
            "coguide photo": "Bhavana C",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg"
        },
        {
            "grpno": 14,
            "title": "AI Assistant for youtube & NPTEL courses",
            "member1": "Nikita Jethani",
            "member2": "Madhusudana Naidu",
            "member3": "Manav Pahilwani",
            "member4": "Shreya Singh",
            "guide": "Ajinkya W",
            "coguide": "Kusum K",
            "description": "This project develops an AI assistant for YouTube lectures and NPTEL videos, offering video summarization and question generation. Learners access concise summaries and engage in interactive Q&A sessions for deeper understanding.  Integration with YouTube and creation of chrome extension ensures seamless access to doubt solving on educational videos. User feedback refines summaries and question generation. The aim is to enhance learning experiences, promote critical thinking, and provide accessible tools for active learning from online educational resources.",
            "github": "https://github.com/E0NIA/AI-Assistant-for-Youtube-Videos",
            "demo": null,
            "domain": "NLP",
            "Research Paper Doc": "https://docs.google.com/document/d/10KOS_BPBuEwfFp4ao0nyssYsbC8_Ss6cx2aBG4eh6xk/edit?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "Nikita Jethani",
            "member2 photo": "Madhusudana Naidu",
            "member3 photo": "Manav Pahilwani",
            "member4 photo": "Shreya Singh",
            "coguide photo": "Kusum K",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg"
        },
        {
            "grpno": 15,
            "title": "Predictive maintenance of servers",
            "member1": "Harshita Anala",
            "member2": "Mahindra Chetwani",
            "member3": "Manas Lalwani",
            "member4": "Parth Suryavanshi",
            "guide": "Dr. Anjali Yeole",
            "coguide": "Himanshi G",
            "description": "Our proposal involves creating a web application that utilises machine sensor data to forecast the likelihood of machine downtime based on the historical data of its servers components . This is going to be carried out by\r\n1. Carry out data cleaning on the data set that includes records of various parameters gathered by the server's sensors, and look for correlations to find patterns related to the server's downtime.\r\n2. Determine and train the best machine learning model that can predict system failure well in advance using the live data supplied to the corresponding model after analysing the data set and determining the correlation.\r\n3. In terms of operations, the model will be highly helpful to the person operating the machine, as well as to their individual managers and other stakeholders.  The project is expected to yield highly efficient results while also saving a significant amount of time.  Profit and productivity as a whole have increased as a result. ",
            "github": null,
            "demo": null,
            "domain": "Predictive maintenance",
            "Research Paper Doc": "https://docs.google.com/document/d/12lpMdo29V86HU1lmmGi7EkL6hY55gu-xRR21Spa_JFE/edit?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/C4E03AQFQex41pJ44fw/profile-displayphoto-shrink_800_800/0/1640583867524?e=1716422400&v=beta&t=1YPUy0gxlFgBQq5XaPuPcoCXryndivOKFKRb0HOVhWE",
            "member2 photo": "Mahindra Chetwani",
            "member3 photo": "Manas Lalwani",
            "member4 photo": "https://media.licdn.com/dms/image/C4D03AQFnB7mzaYm0Kg/profile-displayphoto-shrink_400_400/0/1660965995238?e=1716422400&v=beta&t=_12sWqix8OsLNL_ndqk8IUBsfkm0OtffRDImbJGOsWI",
            "coguide photo": "Himanshi G",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg"
        },
        {
            "grpno": 16,
            "title": "Demysification of neural network through explainable AI",
            "member1": "Priyanshu Singh",
            "member2": "Sneha Kadambala",
            "member3": "Shreyas Satre",
            "member4": "Atharva khangar",
            "guide": "Sangeeta Oswal",
            "coguide": "Bhavana C",
            "description": "Project Title: Demystification of Neural Networks through Explainable AI\r\n\r\nIntroduction:\r\nIn recent years, neural networks have demonstrated remarkable capabilities in various fields, ranging from image recognition to natural language processing. However, the complexity and \"black-box\" nature of neural networks often pose challenges in understanding their decision-making processes, hindering their widespread adoption in critical applications. To address this challenge, our project aims to demystify neural networks using Explainable Artificial Intelligence (XAI) techniques.\r\n\r\nProject Description:\r\n\r\nOur project focuses on creating a transparent understanding of neural networks by leveraging a combination of techniques, including autoencoder architectures, Temporal Convolutional Networks (TCN) for time-series data analysis, SHAP (SHapley Additive exPlanations) for model interpretation, and Natural Language Processing (NLP) for intuitive explanation generation.\r\n\r\n1. Autoencoder Setup with TCN:\r\n\r\nWe begin by constructing an autoencoder architecture tailored for the specific task of analyzing time-series data with 51 feature attributes. Autoencoders are neural networks trained to reconstruct input data, thus learning a compressed representation of the input. We integrate Temporal Convolutional Networks (TCN) within the autoencoder setup to effectively capture temporal dependencies in the time-series data. TCNs are renowned for their ability to model long-range dependencies efficiently, making them suitable for processing sequential data.\r\n\r\n2. SHAP Analysis:\r\n\r\nOnce the autoencoder with TCN is trained on the dataset, we employ (SHapley Additive exPlanations) SHAP values to understand the importance of each feature attribute in the model's decision-making process. SHAP provides a coherent explanation of individual predictions by quantifying the impact of each feature on the model's output. By visualizing SHAP values, users gain insights into how different features influence the neural network's decisions, enhancing transparency and interpretability.\r\n\r\n3. NLP-Based Explanation Generation:\r\n\r\nTo further enhance the interpretability of the neural network's decisions, we leverage Natural Language Processing (NLP) techniques to generate human-readable explanations. By analyzing the learned representations and SHAP values, we extract key insights and transform them into intuitive explanations in natural language. These explanations provide users with actionable insights into the model's behavior, enabling informed decision-making.\r\n\r\nExpected Outcome:\r\n\r\nThrough our project, we aim to achieve the following outcomes:\r\n\r\nEnhanced Understanding: Provide users with a clear understanding of how neural networks operate, particularly in the context of time-series data analysis with multiple features.\r\nTransparency: Offer transparent insights into the decision-making process of the neural network, facilitating trust and confidence in its predictions.\r\nAccessibility: Make complex neural network models accessible to a wider audience by presenting explanations in a comprehensible and intuitive manner.\r\nPractical Utility: Enable stakeholders to make informed decisions based on the insights gleaned from the explainable AI techniques employed in the project.",
            "github": "https://github.com/Shreyassatre/BE-Project-grp-16.git",
            "demo": "https://www.youtube.com/embed/8tw4_AsgXeI?si=krtdLmiIRvTncPxV",
            "domain": "Deep Learning",
            "Research Paper Doc": null,
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/D4D03AQE0jbpf4vjKGA/profile-displayphoto-shrink_400_400/0/1710834423093?e=1716422400&v=beta&t=35XRoz31tP2TJd083sMd2d7s3lxulDh2qX-wSraeTUI",
            "member2 photo": "https://media.licdn.com/dms/image/D5603AQFw5k90oNBbsg/profile-displayphoto-shrink_400_400/0/1710804707136?e=1716422400&v=beta&t=hJtgjoyJa5emTQ-aHC9ccutltUpoZriOtrjOx2rFfNw",
            "member3 photo": "https://media.licdn.com/dms/image/D4D03AQG1pJI8QHSuPA/profile-displayphoto-shrink_400_400/0/1701791736260?e=1716422400&v=beta&t=5nshYwBT-hiL945CGNyrNu0X4lybqE1ixz3J3WsHbF8",
            "member4 photo": "https://drive.google.com/file/d/15-iqEpgNd5YqMghaz8Jprh3ktdbg7mcx/view?usp=drive_link",
            "coguide photo": "Bhavana C",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg"
        },
        {
            "grpno": 17,
            "title": "Aspect Base senitiment Analysis",
            "member1": "Omkar Korade",
            "member2": "Muhammad Faayez",
            "member3": "Harsh Rohra",
            "member4": "Govind Tiwari",
            "guide": "Amit Singh",
            "coguide": "Akansha P",
            "description": "An ML model that compares a student answer and a model answer and gives the accuracy of how similar both annswers are. This can be used by teachers and by anyone who wants to automate the task of grading tests with descriptive answers. The user needs to input both the model answer and student answer either by typing them out or uploading their images. If images are uploaded the model will utilise the OCR functionality to extract the text from them and proceed ahead.",
            "github": "https://github.com/omkarkorde27/MajorProject",
            "demo": null,
            "domain": "NLP",
            "Research Paper Doc": "https://drive.google.com/file/d/1-39psvh70D87A_p35OU5nX1kd1nY8H8j/view?usp=sharing",
            "Fundings Received": false,
            "member1 photo": "https://media.licdn.com/dms/image/D4D03AQEIa1lSbjc25w/profile-displayphoto-shrink_800_800/0/1704370334344?e=1716422400&v=beta&t=WIyAszqK6bdqdAO_-MfFTptca3khYGaOLdYylNfXX0A",
            "member2 photo": "Muhammad Faayez",
            "member3 photo": "https://media.licdn.com/dms/image/D4D03AQHDmU5TEH81dg/profile-displayphoto-shrink_400_400/0/1711119706707?e=1716422400&v=beta&t=H0DvQLsTInd-4NTizIpg9b-eo0s-zLHHhKCGA2b2vJs",
            "member4 photo": "https://media.licdn.com/dms/image/C4D03AQHXejxrYN3J_g/profile-displayphoto-shrink_400_400/0/1661512805935?e=1716422400&v=beta&t=o7ZodhYnAczJbVQnBdGNR3YH-t8SdIqyKVwS6Efk_lo",
            "coguide photo": "Akansha P",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg"
        }
    ],
    "2024-25": [
        {
            "grpno": 1,
            "title": "Predicting Multiple Intelligences using AI",
            "member1": "Kartikee Deshmukh",
            "member2": "Prerna Ladkani",
            "member3": "Prachi Pawar",
            "member4": "Vaishali Sen",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote",
            "description": "Traditional methods for evaluating multiple intelligences, such as fixed-format questionnaires, often fall short in capturing the fluid and complex nature of individual cognitive strengths. Our project addresses this gap by developing an AI-powered chatbot that conducts real-time, adaptive assessments across Howard Gardner’s multiple intelligences—linguistic, logical-mathematical, spatial, musical, bodily-kinesthetic, interpersonal, intrapersonal, and naturalistic.At the core of the system is Gemini Flash 2.0, a powerful large language model (LLM) that enables intelligent, context-aware interactions. Using advanced natural language processing (NLP) and machine learning algorithms, the chatbot dynamically adjusts its line of questioning based on user responses. This adaptive interaction allows the system to probe deeper into specific areas, resulting in a more accurate and detailed intelligence profile. For example, if a user demonstrates strong logical reasoning skills, the system can generate more complex logic-based queries to fine-tune the assessment further.Initial experimental evaluations show that this AI-driven approach not only enhances user engagement but also yields more nuanced insights into cognitive patterns than traditional static questionnaires. The system encourages reflection and active participation, leading to a more authentic assessment of a user's intelligence distribution.Our solution is designed with modularity in mind, allowing for easy integration into existing learning management systems or educational platforms. This adaptability supports the delivery of personalized learning experiences, where educational content can be aligned with each learner’s cognitive strengths and development areas. Such tailored interventions promote better learning outcomes, increased motivation, and more effective educational planning.By merging psychological theory with modern AI capabilities, this project represents a step toward truly personalized education. It offers educators, counselors, and learners a more flexible and interactive tool for understanding and nurturing human intelligence in all its forms.",
            "github": "https://github.com/Kartikee12/Predicating-Multiple-Intelligence-using-AI",
            "demo": "https://www.youtube.com/embed/I8IarsNcgb4",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Kartikee Deshmukh",
            "member2 photo": "Prerna Ladkani",
            "member3 photo": "Prachi Pawar",
            "member4 photo": "Vaishali Sen",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 2,
            "title": "SMARTPARK AI",
            "member1": "Divyam Poptani",
            "member2": "Shreyas Patil",
            "member3": "Niharika Bulani",
            "member4": null,
            "guide": "Mr. Ajinkya Valanjoo",
            "coguide": "Mrs. Puja Vakhare",
            "description": "In urban areas, finding a parking space can be a frustrating and time-consuming task for drivers, often leading to traffic congestion and wasted fuel. Challenges such as real-time slot availability, fair pricing, and efficient navigation add to the complexity. This project, titled \"Smart Park AI\", presents an innovative solution by leveraging YOLO-based AI models to detect vacant parking slots and enable users to book them dynamically. With additional features like voice-assisted booking, multi-language support, real-time safety zone alerts, and a chatbot offering the fastest routes with estimated time and cost, the platform aims to simplify the parking experience and make urban driving more efficient.",
            "github": "https://github.com/dp1013/SMART-PARKAI.git",
            "demo": "https://www.youtube.com/embed/KFZIaJ4ecCA",
            "domain": "Computer Vision",
            "Fundings Received": false,
            "member1 photo": "Divyam Poptani",
            "member2 photo": "Shreyas Patil",
            "member3 photo": "Niharika Bulani",
            "member4 photo": null,
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Puja%20VakharePuja_Vakhare_Photo.jpg"
        },
        {
            "grpno": 3,
            "title": "Democratizing AI for MSMEs with Small E-commerce Language Models",
            "member1": "Ritesh Bhalerao",
            "member2": "Dyotak Kachare",
            "member3": "Sayali Kawatkar",
            "member4": "Aum Kulkarni",
            "guide": "Mrs. Sangeeta Oswal",
            "coguide": "Mrs. Samruddhi Yadav",
            "description": "Micro, Small, and Medium Enterprises (MSMEs), crucial to many economies, face significant barriers in adopting advanced AI technologies due to the high computational and financial costs of large-scale models. This limits their ability to engage with AI-driven innovations. This study empirically demonstrates that SLMs, finetuned on domain-specific datasets, achieve comparable or superior performance to general-purpose LLMs. In support of this stance, we train and test some powerful SLMs across various e-commerce tasks, including sentiment analysis, product recommendation, and attribute extraction as a PoC. In addition to diminished inference costs via SLMs, we also employ Parameter Efficient Fine Tuning via QLoRA to further reduce the training costs for creating domain specific chat models. The resultant models consistently outperform larger models like GPT-4 Turbo and Gemini Pro in domain specific evaluations. By demonstrating that SLMs can deliver competitive results with minimal resources, our research contributes to the broader discourse on AI efficiency, advocating for lightweight, specialized models that balance performance with accessibility.",
            "github": "https://github.com/Riteshbhalerao11/BE_project_24-25",
            "demo": "https://www.youtube.com/embed/h2VG3J-OXf8",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Ritesh Bhalerao",
            "member2 photo": "Dyotak Kachare",
            "member3 photo": "Sayali Kawatkar",
            "member4 photo": "Aum Kulkarni",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Samruddhi%20YadavSamruddhi%20Yadav.jpeg"
        },
        {
            "grpno": 4,
            "title": "Sarcasm Detection",
            "member1": "Arpit Burley",
            "member2": "Manal Kukreja",
            "member3": "Dikshant Kukreja",
            "member4": "Krish Jagwani",
            "guide": "Mrs. Himanshi Jiwatramani",
            "coguide": "Dr Smita Mane",
            "description": "Abstract:\nSarcasm detection is essential for accurate sentiment analysis, especially in social media and online communication where sarcasm is common. This project uses advanced NLP techniques, including transformer-based models like BERT, to identify sarcastic expressions in short texts. By analyzing context, tone, and linguistic patterns, the model aims to improve the understanding of user intent and enhance the performance of AI systems in real-world applications such as content moderation and opinion mining.\n",
            "github": null,
            "demo": "https://drive.google.com/file/d/11Diz6-bTYBQRx3FHO5y8qnzqaCDDo6Eq/preview",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Arpit Burley",
            "member2 photo": "Manal Kukreja",
            "member3 photo": "Dikshant Kukreja",
            "member4 photo": "Krish Jagwani",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Himanshi%20Jiwatramaniphoto_1.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Smita_Mane.jpg"
        },
        {
            "grpno": 5,
            "title": "Mining Misconceptions in Mathematics using LLMs",
            "member1": "Priyanka Amrute",
            "member2": "Disha Bhat",
            "member3": "Mehvish Khan",
            "member4": "Sneha Naik",
            "guide": "Mr. Ajinkya Valanjoo",
            "coguide": "Mrs. Puja Vakhare",
            "description": "Mathematical Misconceptions in education refer to incorrect or incomplete understandings of a concept, which often persist even after students are taught the correct information., thus representing a persistent challenge in education, often impeding students' ability to grasp fundamental concepts and progress in their learning journey. Detecting these misconceptions early can help educators design more targeted interventions to improve student comprehension.This project addresses the problem by utilizing large language models (LLMs) to detect and analyze misconceptions in students' answers. The system allows users to input multiple-choice questions (MCQs) along with the selected options. For each incorrect response, it provides detailed feedback explaining the underlying reason for the error. By pinpointing specific misconceptions, the system offers insights into student behavior and cognitive patterns during assessments, enabling both students and educators to better understand where mistakes are being made. This real-time analysis of student responses provides a powerful tool for teachers to evaluate their students’ mental models and adapt their teaching strategies accordingly. By recognizing common areas of confusion, teachers can implement targeted interventions that address the root causes of misunderstandings, improving overall learning outcomes. Through the integration of LLMs in educational settings, this system enhances the learning experience by addressing cognitive gaps and supporting personalized, data-driven teaching approaches.",
            "github": "https://github.com/mehvishhkhan/BE-Project",
            "demo": "https://www.youtube.com/embed/enoL0omPNM8",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Priyanka Amrute",
            "member2 photo": "Disha Bhat",
            "member3 photo": "Mehvish Khan",
            "member4 photo": "Sneha Naik",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Puja%20VakharePuja_Vakhare_Photo.jpg"
        },
        {
            "grpno": 6,
            "title": "Question Paper generation using Gen AI ang graph RAG",
            "member1": "Arin Choudhary",
            "member2": "Archit Dhar",
            "member3": "Atharva Nawadkar",
            "member4": "Atharva Sardal",
            "guide": "Dr. Anjali Yeole",
            "coguide": "Mrs. Kusum Kardam",
            "description": "In the educational sector, the manual creation of question papers is a time-consuming process that requires\nconsiderable effort from educators. Balancing question difficulty, ensuring comprehensive syllabus\ncoverage, and maintaining fairness are some of the major challenges involved. This project, titled \"Question\nPaper Generation using GEN-AI\", offers an innovative solution by harnessing the power of Generative AI\n(GEN-AI) to automate and streamline the creation of customized question papers.",
            "github": "https://github.com/isosceles45/questionForge.git",
            "demo": "https://www.youtube.com/embed/YRgl51QMLLo",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Arin Choudhary",
            "member2 photo": "Archit Dhar",
            "member3 photo": "Atharva Nawadkar",
            "member4 photo": "Atharva Sardal",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/kusum.jpg"
        },
        {
            "grpno": 7,
            "title": "Personalized AI Tutor",
            "member1": "Shreyas Bhoir",
            "member2": "Abhishek Pattanayak",
            "member3": "Himanshu Goyal",
            "member4": "Atharva Khanvilkar",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote",
            "description": "This project proposes the development of a personalized AI tutor utilizing a Retrieval-Augmented Generation (RAG) framework, aimed at providing a dynamic, adaptive learning experience. The system integrates knowledge hypergraphs, multi-objective retrieval, and generative feedback loops to deliver tailored educational content based on the individual learner's needs and progress. \nBy continuously refining its knowledge base and adjusting pedagogical strategies, the AI tutor can surface deeper knowledge, correct misconceptions, and enhance engagement through real-time adaptation. Additionally, the system incorporates cross-modal content, including videos and quizzes, to create a richer, interactive learning environment. This approach aims to address the limitations of traditional AI tutors, offering a more effective, personalized, and transparent learning tool.",
            "github": "https://github.com/himanshugoyal77/ai-tutor",
            "demo": "https://www.youtube.com/embed/4wEVWqlljuQ",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Shreyas Bhoir",
            "member2 photo": "Abhishek Pattanayak",
            "member3 photo": "Himanshu Goyal",
            "member4 photo": "Atharva Khanvilkar",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 8,
            "title": "UAV Anomaly Detection and Explainability",
            "member1": "Mrunal Shinde",
            "member2": "Rashmit Vartak",
            "member3": "Kapil Bodas",
            "member4": "Chaitali Gaikwd",
            "guide": "Mrs. Sangeeta Oswal",
            "coguide": "Mrs. Samruddhi Yadav",
            "description": "Unmanned Aerial Vehicles (UAVs) rely on robust anomaly detection systems to ensure operational safety and effectiveness. This study presents a hybrid Temporal Convolutional Network with Attention (TCN-A), leveraging global context and temporal dependencies to enhance anomaly classification accuracy. By integrating attention mechanisms, TCN-A prioritizes critical features, improving temporal modeling and capturing complex patterns in sensor data. The model is evaluated on comprehensive datasets covering diverse UAV anomalies, including GPS failures, accelerometer malfunctions, engine issues, and remote control disruptions. While TCN-A demonstrates high performance, its \"black-box\" nature necessitates improved interpretability. To address this, we incorporate eXplainable Artificial Intelligence (XAI) techniques, specifically SHapley Additive exPlanations (SHAP), to uncover key sensor-specific features driving anomaly detection. Our analysis reveals that distinct temporal dynamics—such as gyroscopic deviations, vibration anomalies, and erratic control signals—govern different anomaly classes. XAI not only validates TCN-A’s reliability across heterogeneous sensor data (e.g., IMU, GPS, VIBE) but also provides actionable insights for real-time monitoring and maintenance. By bridging performance and transparency, this work enhances trust in TCN-A’s predictions while informing future improvements in feature engineering and anomaly detection frameworks. The combined approach highlights the importance of interpretable deep learning for UAV safety, ensuring both high accuracy and actionable diagnostics in critical scenarios.",
            "github": "https://github.com/RashmitVartak/BE_Project",
            "demo": "https://www.youtube.com/embed/TFqxvVqfAAc",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Mrunal Shinde",
            "member2 photo": "Rashmit Vartak",
            "member3 photo": "Kapil Bodas",
            "member4 photo": "Chaitali Gaikwd",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Samruddhi%20YadavSamruddhi%20Yadav.jpeg"
        },
        {
            "grpno": 9,
            "title": "Anuvad -A Real Time Gen-AI-Based Translation System\"",
            "member1": "Siddh Ahire",
            "member2": "Manas Deshpande",
            "member3": "Rishabh Gupta",
            "member4": "Shivam Gupta",
            "guide": "Dr. M. Vijayalakshmi",
            "coguide": "Mrs. Bhavana Chaudhari",
            "description": "Real-time speech-to-speech translation is an emerging frontier in machine learning, with advanced neural architectures being in the early stages of application. This project emphasizes ongoing research into Transformer-based models for real-time translation, showcasing a promising yet underutilized approach. Most translation systems still rely on traditional models, as the adoption of modern sequence-to-sequence architectures has been limited due to challenges with latency, computational demands, and managing live data streams. Our research employs a four-module architecture: Speech-to-Text (STT), Translation, Text-to-Speech (TTS), and Speech Output. The STT module captures spoken input and transcribes it into text, which the Transformer-powered translation module processes in real time. The model's contextual understanding enables superior interpretation and translation of nuances, idioms, and culturally sensitive expressions. After translation, the TTS module creates human-like speech for final delivery. This project outlines advancements, challenges, and necessary optimizations aimed at reducing latency and enhancing translation fluency. Additionally, it explores the potential of Transformer-based models to surpass traditional systems in both accuracy and speed while assessing efforts to minimize computational overhead for improved real-time performance, positioning neural sequence models as a cornerstone of next-generation multilingual communication systems.",
            "github": "https://github.com/ShivamGupta82/BE_Major_Project",
            "demo": "https://www.youtube.com/embed/CfKIDcU05F4",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Siddh Ahire",
            "member2 photo": "Manas Deshpande",
            "member3 photo": "Rishabh Gupta",
            "member4 photo": "Shivam Gupta",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/vijayalaxmi.jpeg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Bhavana%20ChaudhariWhatsApp%20Image%202024-12-19%20at%2011.25.18%20AM.jpeg"
        },
        {
            "grpno": 10,
            "title": "Multifaceted Fraud Detection System",
            "member1": "Nihaal Nayak",
            "member2": "Navneet Pujari",
            "member3": "Vignesh Shivhare",
            "member4": "Mukund Tiwari",
            "guide": "Dr. M. Vijayalakshmi",
            "coguide": "Mrs. Bhavana Chaudhari",
            "description": "Combines Natural Language Processing (NLP) with Graph Neural Networks (GNNs - The solution analyzes both content features (using textual embeddings from models like BERT) and propagation patterns (through Graph Attention Networks) to identify sophisticated fake media. By processing Politifact data and social media interactions, the system detects inconsistencies between content and its dissemination context, effectively uncovering coordinated disinformation campaign",
            "github": "https://github.com/vigneshshiv28/BE-project",
            "demo": "https://www.youtube.com/embed/DlcDZ0LUkW0",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Nihaal Nayak",
            "member2 photo": "Navneet Pujari",
            "member3 photo": "Vignesh Shivhare",
            "member4 photo": "Mukund Tiwari",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/vijayalaxmi.jpeg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Bhavana%20ChaudhariWhatsApp%20Image%202024-12-19%20at%2011.25.18%20AM.jpeg"
        },
        {
            "grpno": 11,
            "title": "MYSPACE- GenAI Interior Designing",
            "member1": "Prathmesh Dubey",
            "member2": "Sahil Gupta",
            "member3": "Manas Mahajan",
            "member4": "Ajay Nambiar",
            "guide": "Mr. Ajinkya Valanjoo",
            "coguide": "Mrs. Puja Vakhare\r",
            "description": "By embracing cultural diversity and traditional aesthetics—often overlooked by mainstream design tools that prioritize modern minimalism—the MySPACE platform offers a refreshing approach to interior design. It enables individuals to celebrate their heritage and personal values through their living spaces, creating interiors that are not only visually appealing but also deeply meaningful. MySPACE provides an intuitive, AI-powered interface that invites users to contribute creative input through various methods, such as written prompts, sketches, or reference images. These inputs are processed using sophisticated generative models like Kandinsky-2-2-Prior and ControlNet, implemented via the Diffusers library, which collectively convert these ideas into high-resolution, customized visual outputs. These models fine-tune essential design aspects—such as texture, color schemes, material types, and lighting ambiance—to reflect the user’s intent and desired aesthetic. To ensure secure and efficient performance, all image generation and transformation processes are executed through the Hugging Face API. This not only guarantees the reliability and safety of the platform but also supports its ability to deliver high-quality results consistently. What sets MySPACE apart is its commitment to inclusivity and cultural sensitivity. By merging advanced machine learning techniques with an understanding of diverse design traditions, it enables users from different cultural backgrounds to see their identities reflected in modern interior spaces. The platform supports an iterative approach to design, allowing users to continually refine their input and receive updated visualizations, enhancing both creativity and engagement. In bridging traditional aesthetics with cutting-edge AI technology, MySPACE empowers users to craft spaces that are truly their own—rich in cultural depth, visually unique, and aligned with personal identity. It stands as a compelling example of how technology can be harnessed not just for functionality, but for meaningful self-expression in the home.",
            "github": "https://github.com/sahilcreator07/MySpace.git",
            "demo": "https://www.youtube.com/embed/E1A0egdvfPY",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Prathmesh Dubey",
            "member2 photo": "Sahil Gupta",
            "member3 photo": "Manas Mahajan",
            "member4 photo": "Ajay Nambiar",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Puja%20VakharePuja_Vakhare_Photo.jpg"
        },
        {
            "grpno": 12,
            "title": "Intelligent Tutoring System",
            "member1": "Parth Kadam",
            "member2": "Vedant Kalwar",
            "member3": "Nikhil Thakur",
            "member4": "Rutik Jaybhaye",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote ",
            "description": "This project presents the development of an Intelligent Tutoring System (ITS) designed to enhance personalized learning through adaptive content generation. The system employs a dynamic assessment mechanism to evaluate student performance on tests and quizzes. Based on these assessments, the system generates tailored educational content that adjusts in complexity to address individual learning needs. If a student scores below a predetermined threshold, the system simplifies the content to better align with their current understanding and provide additional practice. This adaptive approach aims to improve learning outcomes by ensuring that educational materials are both accessible and effective for each student. The project integrates content generation techniques and performance tracking to create a responsive and supportive learning environment.",
            "github": "https://github.com/Parth18062003/Tutoring_System",
            "demo": "https://www.youtube.com/embed/Ytb6hxRx3X0",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Parth Kadam",
            "member2 photo": "Vedant Kalwar",
            "member3 photo": "Nikhil Thakur",
            "member4 photo": "Rutik Jaybhaye",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 13,
            "title": "Simu-Twin: Anomaly detection in water treatment plants using Digital Twin",
            "member1": "Ashish Patil",
            "member2": "Ria Khetani",
            "member3": "Shreya Pawaskar",
            "member4": "Atharva Baheti",
            "guide": "Mrs. Sangeeta Oswal",
            "coguide": "Mrs. Samruddhi Yadav",
            "description": "SCADA and Cyber Physical system are critical infrastructures where operational continuity and safety are paramount. However, these systems are prone to various operational anomalies, including equipment failures and cyberattacks, which can severely compromise quality. Simu-Twin is a comprehensive solution designed to enhance anomaly detection in water treatment plants through the integration of Digital Twin technology. Simu-Twin leverages real-time sensor data to flag anomalous data points using long-short-term memory (LSTM) networks. The model is tested on a water treatment dataset called the secure water treatment (SWaT) system. Simu-Twin incorporates a Digital Twin Setup built with React and a Flask. The digital Twin Setup reflects the current sensor readings processed by the LSTM model and the identified anomalies by the model are reflected in the twin to facilitate the end user to mitigate the attack. The Digital Twin system provides operators with an intuitive interface to monitor the status of the plant and receive alerts on potential threats or deviations. The test accuracy of 94.66 percent is achieved on the SWaT Dataset. The research demonstrates the model’s exceptional accuracy in identifying anomalous patterns, contributing to enhanced security and reliability of water treatment infrastructure. By leveraging the strengths of both DNNs and Digital twin, our model provides a robust foundation for developing security systems capable of detecting threats to water quality and public health.",
            "github": "https://github.com/Ashtrobuff/Simu-Twin",
            "demo": "https://www.youtube.com/embed/xUt2ml5gFkk",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Ashish Patil",
            "member2 photo": "Ria Khetani",
            "member3 photo": "Shreya Pawaskar",
            "member4 photo": "Atharva Baheti",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Samruddhi%20YadavSamruddhi%20Yadav.jpeg"
        },
        {
            "grpno": 14,
            "title": "Lawgarithm - One stop solution for all your legal queries and assistance",
            "member1": "Alok Kale",
            "member2": "Shreeprasad Navare",
            "member3": "Khalid Sayyed",
            "member4": "Soham Shetty",
            "guide": "Dr. Mrs. Anjali Yeole",
            "coguide": "Mrs. Kusum Kardam",
            "description": "Navigating Indian law is complex and time-consuming, requiring deep legal expertise. This project develops an AI-powered legal assistant fine-tuned for Indian law using a custom-trained Large Language Model (LLM). The AI analyzes crime descriptions and suggests precise legal charges across various frameworks, enriched with case studies and legal knowledge. It aims to assist legal professionals, students, and individuals by improving accessibility and reducing the burden of legal analysis.",
            "github": "https://github.com/nSHREEPRASAD/BE_PROJECT_14",
            "demo": "https://www.youtube.com/embed/Gk2zHtWzoRM",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Alok Kale",
            "member2 photo": "Shreeprasad Navare",
            "member3 photo": "Khalid Sayyed",
            "member4 photo": "Soham Shetty",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/kusum.jpg"
        },
        {
            "grpno": 15,
            "title": "Automating Answer Assessment",
            "member1": "Khushi Bajaj",
            "member2": "Rohit Bhomkar",
            "member3": "Harsh Jain",
            "member4": "Tarun Aswani",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote",
            "description": "Automated answer assessment has gained significant traction in educational technology, aiming to reduce manual grading effort and ensure consistent evaluation. However, a critical limitation in many existing systems is the lack of explainability, making it difficult for students and educators to understand grading decisions. This project addresses that gap by designing an explainable automated assessment framework powered by large language models (LLMs), specifically Mistral AI. The system dynamically assigns evaluation weightage to key grading traits—Content Accuracy, Coherence & Structure, Vocabulary & Clarity, and Grammar & Language—based on question complexity. It then compares student responses with model answers, providing detailed feedback and improvement suggestions for each trait, along with a transparent score breakdown. By combining dynamic trait weighting with trait-specific commentary, the framework enhances both the fairness and interpretability of automated evaluations. This approach offers a promising step toward more trustworthy and pedagogically valuable AI-assisted assessment tools.",
            "github": "https://github.com/NeoZ666/Major-Project-BE",
            "demo": "https://www.youtube.com/embed/XTF2qz9sHSI",
            "domain": "Explainable AI",
            "Fundings Received": false,
            "member1 photo": "Khushi Bajaj",
            "member2 photo": "Rohit Bhomkar",
            "member3 photo": "Harsh Jain",
            "member4 photo": "Tarun Aswani",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 16,
            "title": "AI-Driven Portfolio Optimization",
            "member1": "Akshay Gurnani",
            "member2": "Deepak Rajani",
            "member3": "Tanvi Sangale",
            "member4": "Piyush Batheja",
            "guide": "Mrs. Kanchan Chavan",
            "coguide": "Mrs. Bhagyashree",
            "description": "The project focuses on AI-driven portfolio optimization by predicting stock prices using LSTM models and selecting top-performing stocks from real-time Yahoo Finance data. 50,000 random portfolios are generated, and Mean-Variance Optimization is applied to select the portfolio with the best risk-return balance. Python libraries like NumPy, SciPy, and TensorFlow are used. The final output is an optimal, diversified investment portfolio.",
            "github": null,
            "demo": "https://www.youtube.com/embed/mBPXrH0utMY",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Akshay Gurnani",
            "member2 photo": "Deepak Rajani",
            "member3 photo": "Tanvi Sangale",
            "member4 photo": "Piyush Batheja",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585240237Kanchan%20Chavan.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20BhagyashreeIMG_20241218_195653.jpg"
        },
        {
            "grpno": 17,
            "title": "NeuroTumorAI:Prediction Segmentation and Classification Of Brain Tumors",
            "member1": "Gaurav Malpedi",
            "member2": "Suhanee Kandalkar",
            "member3": "Rohit Kshatriya",
            "member4": "Srirag Nair",
            "guide": "Mrs. Neeta Chavan",
            "coguide": "Mrs. Bhagyashree",
            "description": "Brain tumors are serious medical conditions where early and precise detection is vital for effective treatment. While predicting the stage of a tumor remains complex, our research focuses on developing a machine learning system capable of segmentation of different types of brain tumors based on MRI scans. By leveraging advanced algorithms, the system aims to assist in accurately identifying tumor types, thereby supporting doctors in making faster and more informed decisions, ultimately improving patient care and treatment planning.",
            "github": "https://github.com/DrizzyOVO/BeProjModel",
            "demo": "https://www.youtube.com/embed/H73-jodbesY",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Gaurav Malpedi",
            "member2 photo": "Suhanee Kandalkar",
            "member3 photo": "Rohit Kshatriya",
            "member4 photo": "Srirag Nair",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585252511Neeta%20Chavan.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20BhagyashreeIMG_20241218_195653.jpg"
        },
        {
            "grpno": 18,
            "title": "AI Driven Early Detection Of Colorectal Cancer",
            "member1": "Sanika Dhuri",
            "member2": "Swayam Gaikwad",
            "member3": "Khyati Hegde",
            "member4": "Anjali Parwani",
            "guide": "Dr. Anjali Yeole",
            "coguide": "Mrs. Kusum Kardam",
            "description": "Colorectal cancer (CRC) is the second leading cause of cancer-related deaths globally, largely due to delayed diagnosis and reliance on manual histopathological analysis, which can be both time-consuming and prone to human error. To address this, we propose a two-stage AI-driven deep learning framework for automated CRC detection and risk assessment using histopathological and endoscopic imagery. In the first stage, a ResNet-50-based Convolutional Neural Network (CNN) classifies tissue images from the NCT-CRC-HE-100K dataset into nine categories, including tumor epithelium and stroma, with validation from CRC-VAL-HE-7K. If no cancer is detected, the second stage initiates, employing a Vision Transformer (ViT) model to analyze gastrointestinal images from the Kvasir-V2 dataset, identifying polyps—potential precursors to CRC.\nTo foster trust and transparency in medical decision-making, we incorporate Local Interpretable Model-Agnostic Explanations (LIME), which visually highlight critical regions influencing the model’s output. Additionally, a Retrieval-Augmented Generation (RAG) pipeline supports a Q&A system that retrieves contextual medical knowledge for enhanced user understanding. Results show the ResNet-50 model achieving over 90% classification accuracy and the ViT model reaching 93.5%, confirming the reliability of our framework. This pipeline not only improves diagnostic precision and reduces pathologist workload but also empowers early intervention through interpretable AI and real-time knowledge retrieval—making it a valuable asset for clinical decision support in colorectal cancer care.",
            "github": "https://github.com/Snika987/Final-Year-Project",
            "demo": "https://www.youtube.com/embed/5eqVIailUpc",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Sanika Dhuri",
            "member2 photo": "Swayam Gaikwad",
            "member3 photo": "Khyati Hegde",
            "member4 photo": "Anjali Parwani",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/kusum.jpg"
        }
    ],
    "2025-26": [
        {
            "grpno": 1,
            "title": "Predicting Multiple Intelligences using AI",
            "member1": "Kartikee Deshmukh",
            "member2": "Prerna Ladkani",
            "member3": "Prachi Pawar",
            "member4": "Vaishali Sen",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote",
            "description": "Traditional methods for evaluating multiple intelligences, such as fixed-format questionnaires, often fall short in capturing the fluid and complex nature of individual cognitive strengths. Our project addresses this gap by developing an AI-powered chatbot that conducts real-time, adaptive assessments across Howard Gardner’s multiple intelligences—linguistic, logical-mathematical, spatial, musical, bodily-kinesthetic, interpersonal, intrapersonal, and naturalistic.At the core of the system is Gemini Flash 2.0, a powerful large language model (LLM) that enables intelligent, context-aware interactions. Using advanced natural language processing (NLP) and machine learning algorithms, the chatbot dynamically adjusts its line of questioning based on user responses. This adaptive interaction allows the system to probe deeper into specific areas, resulting in a more accurate and detailed intelligence profile. For example, if a user demonstrates strong logical reasoning skills, the system can generate more complex logic-based queries to fine-tune the assessment further.Initial experimental evaluations show that this AI-driven approach not only enhances user engagement but also yields more nuanced insights into cognitive patterns than traditional static questionnaires. The system encourages reflection and active participation, leading to a more authentic assessment of a user's intelligence distribution.Our solution is designed with modularity in mind, allowing for easy integration into existing learning management systems or educational platforms. This adaptability supports the delivery of personalized learning experiences, where educational content can be aligned with each learner’s cognitive strengths and development areas. Such tailored interventions promote better learning outcomes, increased motivation, and more effective educational planning.By merging psychological theory with modern AI capabilities, this project represents a step toward truly personalized education. It offers educators, counselors, and learners a more flexible and interactive tool for understanding and nurturing human intelligence in all its forms.",
            "github": "https://github.com/Kartikee12/Predicating-Multiple-Intelligence-using-AI",
            "demo": "https://www.youtube.com/embed/I8IarsNcgb4",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Kartikee Deshmukh",
            "member2 photo": "Prerna Ladkani",
            "member3 photo": "Prachi Pawar",
            "member4 photo": "Vaishali Sen",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 2,
            "title": "SMARTPARK AI",
            "member1": "Divyam Poptani",
            "member2": "Shreyas Patil",
            "member3": "Niharika Bulani",
            "member4": null,
            "guide": "Mr. Ajinkya Valanjoo",
            "coguide": "Mrs. Puja Vakhare",
            "description": "In urban areas, finding a parking space can be a frustrating and time-consuming task for drivers, often leading to traffic congestion and wasted fuel. Challenges such as real-time slot availability, fair pricing, and efficient navigation add to the complexity. This project, titled \"Smart Park AI\", presents an innovative solution by leveraging YOLO-based AI models to detect vacant parking slots and enable users to book them dynamically. With additional features like voice-assisted booking, multi-language support, real-time safety zone alerts, and a chatbot offering the fastest routes with estimated time and cost, the platform aims to simplify the parking experience and make urban driving more efficient.",
            "github": "https://github.com/dp1013/SMART-PARKAI.git",
            "demo": "https://www.youtube.com/embed/KFZIaJ4ecCA",
            "domain": "Computer Vision",
            "Fundings Received": false,
            "member1 photo": "Divyam Poptani",
            "member2 photo": "Shreyas Patil",
            "member3 photo": "Niharika Bulani",
            "member4 photo": null,
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Puja%20VakharePuja_Vakhare_Photo.jpg"
        },
        {
            "grpno": 3,
            "title": "Democratizing AI for MSMEs with Small E-commerce Language Models",
            "member1": "Ritesh Bhalerao",
            "member2": "Dyotak Kachare",
            "member3": "Sayali Kawatkar",
            "member4": "Aum Kulkarni",
            "guide": "Mrs. Sangeeta Oswal",
            "coguide": "Mrs. Samruddhi Yadav",
            "description": "Micro, Small, and Medium Enterprises (MSMEs), crucial to many economies, face significant barriers in adopting advanced AI technologies due to the high computational and financial costs of large-scale models. This limits their ability to engage with AI-driven innovations. This study empirically demonstrates that SLMs, finetuned on domain-specific datasets, achieve comparable or superior performance to general-purpose LLMs. In support of this stance, we train and test some powerful SLMs across various e-commerce tasks, including sentiment analysis, product recommendation, and attribute extraction as a PoC. In addition to diminished inference costs via SLMs, we also employ Parameter Efficient Fine Tuning via QLoRA to further reduce the training costs for creating domain specific chat models. The resultant models consistently outperform larger models like GPT-4 Turbo and Gemini Pro in domain specific evaluations. By demonstrating that SLMs can deliver competitive results with minimal resources, our research contributes to the broader discourse on AI efficiency, advocating for lightweight, specialized models that balance performance with accessibility.",
            "github": "https://github.com/Riteshbhalerao11/BE_project_24-25",
            "demo": "https://www.youtube.com/embed/h2VG3J-OXf8",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Ritesh Bhalerao",
            "member2 photo": "Dyotak Kachare",
            "member3 photo": "Sayali Kawatkar",
            "member4 photo": "Aum Kulkarni",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Samruddhi%20YadavSamruddhi%20Yadav.jpeg"
        },
        {
            "grpno": 4,
            "title": "Sarcasm Detection",
            "member1": "Arpit Burley",
            "member2": "Manal Kukreja",
            "member3": "Dikshant Kukreja",
            "member4": "Krish Jagwani",
            "guide": "Mrs. Himanshi Jiwatramani",
            "coguide": "Dr Smita Mane",
            "description": "Abstract:\nSarcasm detection is essential for accurate sentiment analysis, especially in social media and online communication where sarcasm is common. This project uses advanced NLP techniques, including transformer-based models like BERT, to identify sarcastic expressions in short texts. By analyzing context, tone, and linguistic patterns, the model aims to improve the understanding of user intent and enhance the performance of AI systems in real-world applications such as content moderation and opinion mining.\n",
            "github": null,
            "demo": "https://drive.google.com/file/d/11Diz6-bTYBQRx3FHO5y8qnzqaCDDo6Eq/preview",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Arpit Burley",
            "member2 photo": "Manal Kukreja",
            "member3 photo": "Dikshant Kukreja",
            "member4 photo": "Krish Jagwani",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Himanshi%20Jiwatramaniphoto_1.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Smita_Mane.jpg"
        },
        {
            "grpno": 5,
            "title": "Mining Misconceptions in Mathematics using LLMs",
            "member1": "Priyanka Amrute",
            "member2": "Disha Bhat",
            "member3": "Mehvish Khan",
            "member4": "Sneha Naik",
            "guide": "Mr. Ajinkya Valanjoo",
            "coguide": "Mrs. Puja Vakhare",
            "description": "Mathematical Misconceptions in education refer to incorrect or incomplete understandings of a concept, which often persist even after students are taught the correct information., thus representing a persistent challenge in education, often impeding students' ability to grasp fundamental concepts and progress in their learning journey. Detecting these misconceptions early can help educators design more targeted interventions to improve student comprehension.This project addresses the problem by utilizing large language models (LLMs) to detect and analyze misconceptions in students' answers. The system allows users to input multiple-choice questions (MCQs) along with the selected options. For each incorrect response, it provides detailed feedback explaining the underlying reason for the error. By pinpointing specific misconceptions, the system offers insights into student behavior and cognitive patterns during assessments, enabling both students and educators to better understand where mistakes are being made. This real-time analysis of student responses provides a powerful tool for teachers to evaluate their students’ mental models and adapt their teaching strategies accordingly. By recognizing common areas of confusion, teachers can implement targeted interventions that address the root causes of misunderstandings, improving overall learning outcomes. Through the integration of LLMs in educational settings, this system enhances the learning experience by addressing cognitive gaps and supporting personalized, data-driven teaching approaches.",
            "github": "https://github.com/mehvishhkhan/BE-Project",
            "demo": "https://www.youtube.com/embed/enoL0omPNM8",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Priyanka Amrute",
            "member2 photo": "Disha Bhat",
            "member3 photo": "Mehvish Khan",
            "member4 photo": "Sneha Naik",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Puja%20VakharePuja_Vakhare_Photo.jpg"
        },
        {
            "grpno": 6,
            "title": "Question Paper generation using Gen AI ang graph RAG",
            "member1": "Arin Choudhary",
            "member2": "Archit Dhar",
            "member3": "Atharva Nawadkar",
            "member4": "Atharva Sardal",
            "guide": "Dr. Anjali Yeole",
            "coguide": "Mrs. Kusum Kardam",
            "description": "In the educational sector, the manual creation of question papers is a time-consuming process that requires\nconsiderable effort from educators. Balancing question difficulty, ensuring comprehensive syllabus\ncoverage, and maintaining fairness are some of the major challenges involved. This project, titled \"Question\nPaper Generation using GEN-AI\", offers an innovative solution by harnessing the power of Generative AI\n(GEN-AI) to automate and streamline the creation of customized question papers.",
            "github": "https://github.com/isosceles45/questionForge.git",
            "demo": "https://www.youtube.com/embed/YRgl51QMLLo",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Arin Choudhary",
            "member2 photo": "Archit Dhar",
            "member3 photo": "Atharva Nawadkar",
            "member4 photo": "Atharva Sardal",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/kusum.jpg"
        },
        {
            "grpno": 7,
            "title": "Personalized AI Tutor",
            "member1": "Shreyas Bhoir",
            "member2": "Abhishek Pattanayak",
            "member3": "Himanshu Goyal",
            "member4": "Atharva Khanvilkar",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote",
            "description": "This project proposes the development of a personalized AI tutor utilizing a Retrieval-Augmented Generation (RAG) framework, aimed at providing a dynamic, adaptive learning experience. The system integrates knowledge hypergraphs, multi-objective retrieval, and generative feedback loops to deliver tailored educational content based on the individual learner's needs and progress. \nBy continuously refining its knowledge base and adjusting pedagogical strategies, the AI tutor can surface deeper knowledge, correct misconceptions, and enhance engagement through real-time adaptation. Additionally, the system incorporates cross-modal content, including videos and quizzes, to create a richer, interactive learning environment. This approach aims to address the limitations of traditional AI tutors, offering a more effective, personalized, and transparent learning tool.",
            "github": "https://github.com/himanshugoyal77/ai-tutor",
            "demo": "https://www.youtube.com/embed/4wEVWqlljuQ",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Shreyas Bhoir",
            "member2 photo": "Abhishek Pattanayak",
            "member3 photo": "Himanshu Goyal",
            "member4 photo": "Atharva Khanvilkar",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 8,
            "title": "UAV Anomaly Detection and Explainability",
            "member1": "Mrunal Shinde",
            "member2": "Rashmit Vartak",
            "member3": "Kapil Bodas",
            "member4": "Chaitali Gaikwd",
            "guide": "Mrs. Sangeeta Oswal",
            "coguide": "Mrs. Samruddhi Yadav",
            "description": "Unmanned Aerial Vehicles (UAVs) rely on robust anomaly detection systems to ensure operational safety and effectiveness. This study presents a hybrid Temporal Convolutional Network with Attention (TCN-A), leveraging global context and temporal dependencies to enhance anomaly classification accuracy. By integrating attention mechanisms, TCN-A prioritizes critical features, improving temporal modeling and capturing complex patterns in sensor data. The model is evaluated on comprehensive datasets covering diverse UAV anomalies, including GPS failures, accelerometer malfunctions, engine issues, and remote control disruptions. While TCN-A demonstrates high performance, its \"black-box\" nature necessitates improved interpretability. To address this, we incorporate eXplainable Artificial Intelligence (XAI) techniques, specifically SHapley Additive exPlanations (SHAP), to uncover key sensor-specific features driving anomaly detection. Our analysis reveals that distinct temporal dynamics—such as gyroscopic deviations, vibration anomalies, and erratic control signals—govern different anomaly classes. XAI not only validates TCN-A’s reliability across heterogeneous sensor data (e.g., IMU, GPS, VIBE) but also provides actionable insights for real-time monitoring and maintenance. By bridging performance and transparency, this work enhances trust in TCN-A’s predictions while informing future improvements in feature engineering and anomaly detection frameworks. The combined approach highlights the importance of interpretable deep learning for UAV safety, ensuring both high accuracy and actionable diagnostics in critical scenarios.",
            "github": "https://github.com/RashmitVartak/BE_Project",
            "demo": "https://www.youtube.com/embed/TFqxvVqfAAc",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Mrunal Shinde",
            "member2 photo": "Rashmit Vartak",
            "member3 photo": "Kapil Bodas",
            "member4 photo": "Chaitali Gaikwd",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Samruddhi%20YadavSamruddhi%20Yadav.jpeg"
        },
        {
            "grpno": 9,
            "title": "Anuvad -A Real Time Gen-AI-Based Translation System\"",
            "member1": "Siddh Ahire",
            "member2": "Manas Deshpande",
            "member3": "Rishabh Gupta",
            "member4": "Shivam Gupta",
            "guide": "Dr. M. Vijayalakshmi",
            "coguide": "Mrs. Bhavana Chaudhari",
            "description": "Real-time speech-to-speech translation is an emerging frontier in machine learning, with advanced neural architectures being in the early stages of application. This project emphasizes ongoing research into Transformer-based models for real-time translation, showcasing a promising yet underutilized approach. Most translation systems still rely on traditional models, as the adoption of modern sequence-to-sequence architectures has been limited due to challenges with latency, computational demands, and managing live data streams. Our research employs a four-module architecture: Speech-to-Text (STT), Translation, Text-to-Speech (TTS), and Speech Output. The STT module captures spoken input and transcribes it into text, which the Transformer-powered translation module processes in real time. The model's contextual understanding enables superior interpretation and translation of nuances, idioms, and culturally sensitive expressions. After translation, the TTS module creates human-like speech for final delivery. This project outlines advancements, challenges, and necessary optimizations aimed at reducing latency and enhancing translation fluency. Additionally, it explores the potential of Transformer-based models to surpass traditional systems in both accuracy and speed while assessing efforts to minimize computational overhead for improved real-time performance, positioning neural sequence models as a cornerstone of next-generation multilingual communication systems.",
            "github": "https://github.com/ShivamGupta82/BE_Major_Project",
            "demo": "https://www.youtube.com/embed/CfKIDcU05F4",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Siddh Ahire",
            "member2 photo": "Manas Deshpande",
            "member3 photo": "Rishabh Gupta",
            "member4 photo": "Shivam Gupta",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/vijayalaxmi.jpeg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Bhavana%20ChaudhariWhatsApp%20Image%202024-12-19%20at%2011.25.18%20AM.jpeg"
        },
        {
            "grpno": 10,
            "title": "Multifaceted Fraud Detection System",
            "member1": "Nihaal Nayak",
            "member2": "Navneet Pujari",
            "member3": "Vignesh Shivhare",
            "member4": "Mukund Tiwari",
            "guide": "Dr. M. Vijayalakshmi",
            "coguide": "Mrs. Bhavana Chaudhari",
            "description": "Combines Natural Language Processing (NLP) with Graph Neural Networks (GNNs - The solution analyzes both content features (using textual embeddings from models like BERT) and propagation patterns (through Graph Attention Networks) to identify sophisticated fake media. By processing Politifact data and social media interactions, the system detects inconsistencies between content and its dissemination context, effectively uncovering coordinated disinformation campaign",
            "github": "https://github.com/vigneshshiv28/BE-project",
            "demo": "https://www.youtube.com/embed/DlcDZ0LUkW0",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Nihaal Nayak",
            "member2 photo": "Navneet Pujari",
            "member3 photo": "Vignesh Shivhare",
            "member4 photo": "Mukund Tiwari",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/vijayalaxmi.jpeg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Bhavana%20ChaudhariWhatsApp%20Image%202024-12-19%20at%2011.25.18%20AM.jpeg"
        },
        {
            "grpno": 11,
            "title": "MYSPACE- GenAI Interior Designing",
            "member1": "Prathmesh Dubey",
            "member2": "Sahil Gupta",
            "member3": "Manas Mahajan",
            "member4": "Ajay Nambiar",
            "guide": "Mr. Ajinkya Valanjoo",
            "coguide": "Mrs. Puja Vakhare\r",
            "description": "By embracing cultural diversity and traditional aesthetics—often overlooked by mainstream design tools that prioritize modern minimalism—the MySPACE platform offers a refreshing approach to interior design. It enables individuals to celebrate their heritage and personal values through their living spaces, creating interiors that are not only visually appealing but also deeply meaningful. MySPACE provides an intuitive, AI-powered interface that invites users to contribute creative input through various methods, such as written prompts, sketches, or reference images. These inputs are processed using sophisticated generative models like Kandinsky-2-2-Prior and ControlNet, implemented via the Diffusers library, which collectively convert these ideas into high-resolution, customized visual outputs. These models fine-tune essential design aspects—such as texture, color schemes, material types, and lighting ambiance—to reflect the user’s intent and desired aesthetic. To ensure secure and efficient performance, all image generation and transformation processes are executed through the Hugging Face API. This not only guarantees the reliability and safety of the platform but also supports its ability to deliver high-quality results consistently. What sets MySPACE apart is its commitment to inclusivity and cultural sensitivity. By merging advanced machine learning techniques with an understanding of diverse design traditions, it enables users from different cultural backgrounds to see their identities reflected in modern interior spaces. The platform supports an iterative approach to design, allowing users to continually refine their input and receive updated visualizations, enhancing both creativity and engagement. In bridging traditional aesthetics with cutting-edge AI technology, MySPACE empowers users to craft spaces that are truly their own—rich in cultural depth, visually unique, and aligned with personal identity. It stands as a compelling example of how technology can be harnessed not just for functionality, but for meaningful self-expression in the home.",
            "github": "https://github.com/sahilcreator07/MySpace.git",
            "demo": "https://www.youtube.com/embed/E1A0egdvfPY",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Prathmesh Dubey",
            "member2 photo": "Sahil Gupta",
            "member3 photo": "Manas Mahajan",
            "member4 photo": "Ajay Nambiar",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585259817Ajinkya%20V.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Puja%20VakharePuja_Vakhare_Photo.jpg"
        },
        {
            "grpno": 12,
            "title": "Intelligent Tutoring System",
            "member1": "Parth Kadam",
            "member2": "Vedant Kalwar",
            "member3": "Nikhil Thakur",
            "member4": "Rutik Jaybhaye",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote ",
            "description": "This project presents the development of an Intelligent Tutoring System (ITS) designed to enhance personalized learning through adaptive content generation. The system employs a dynamic assessment mechanism to evaluate student performance on tests and quizzes. Based on these assessments, the system generates tailored educational content that adjusts in complexity to address individual learning needs. If a student scores below a predetermined threshold, the system simplifies the content to better align with their current understanding and provide additional practice. This adaptive approach aims to improve learning outcomes by ensuring that educational materials are both accessible and effective for each student. The project integrates content generation techniques and performance tracking to create a responsive and supportive learning environment.",
            "github": "https://github.com/Parth18062003/Tutoring_System",
            "demo": "https://www.youtube.com/embed/Ytb6hxRx3X0",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Parth Kadam",
            "member2 photo": "Vedant Kalwar",
            "member3 photo": "Nikhil Thakur",
            "member4 photo": "Rutik Jaybhaye",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 13,
            "title": "Simu-Twin: Anomaly detection in water treatment plants using Digital Twin",
            "member1": "Ashish Patil",
            "member2": "Ria Khetani",
            "member3": "Shreya Pawaskar",
            "member4": "Atharva Baheti",
            "guide": "Mrs. Sangeeta Oswal",
            "coguide": "Mrs. Samruddhi Yadav",
            "description": "SCADA and Cyber Physical system are critical infrastructures where operational continuity and safety are paramount. However, these systems are prone to various operational anomalies, including equipment failures and cyberattacks, which can severely compromise quality. Simu-Twin is a comprehensive solution designed to enhance anomaly detection in water treatment plants through the integration of Digital Twin technology. Simu-Twin leverages real-time sensor data to flag anomalous data points using long-short-term memory (LSTM) networks. The model is tested on a water treatment dataset called the secure water treatment (SWaT) system. Simu-Twin incorporates a Digital Twin Setup built with React and a Flask. The digital Twin Setup reflects the current sensor readings processed by the LSTM model and the identified anomalies by the model are reflected in the twin to facilitate the end user to mitigate the attack. The Digital Twin system provides operators with an intuitive interface to monitor the status of the plant and receive alerts on potential threats or deviations. The test accuracy of 94.66 percent is achieved on the SWaT Dataset. The research demonstrates the model’s exceptional accuracy in identifying anomalous patterns, contributing to enhanced security and reliability of water treatment infrastructure. By leveraging the strengths of both DNNs and Digital twin, our model provides a robust foundation for developing security systems capable of detecting threats to water quality and public health.",
            "github": "https://github.com/Ashtrobuff/Simu-Twin",
            "demo": "https://www.youtube.com/embed/xUt2ml5gFkk",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Ashish Patil",
            "member2 photo": "Ria Khetani",
            "member3 photo": "Shreya Pawaskar",
            "member4 photo": "Atharva Baheti",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1587730043Sangeeta%20Oswal.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Samruddhi%20YadavSamruddhi%20Yadav.jpeg"
        },
        {
            "grpno": 14,
            "title": "Lawgarithm - One stop solution for all your legal queries and assistance",
            "member1": "Alok Kale",
            "member2": "Shreeprasad Navare",
            "member3": "Khalid Sayyed",
            "member4": "Soham Shetty",
            "guide": "Dr. Mrs. Anjali Yeole",
            "coguide": "Mrs. Kusum Kardam",
            "description": "Navigating Indian law is complex and time-consuming, requiring deep legal expertise. This project develops an AI-powered legal assistant fine-tuned for Indian law using a custom-trained Large Language Model (LLM). The AI analyzes crime descriptions and suggests precise legal charges across various frameworks, enriched with case studies and legal knowledge. It aims to assist legal professionals, students, and individuals by improving accessibility and reducing the burden of legal analysis.",
            "github": "https://github.com/nSHREEPRASAD/BE_PROJECT_14",
            "demo": "https://www.youtube.com/embed/Gk2zHtWzoRM",
            "domain": "NLP",
            "Fundings Received": false,
            "member1 photo": "Alok Kale",
            "member2 photo": "Shreeprasad Navare",
            "member3 photo": "Khalid Sayyed",
            "member4 photo": "Soham Shetty",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/kusum.jpg"
        },
        {
            "grpno": 15,
            "title": "Automating Answer Assessment",
            "member1": "Khushi Bajaj",
            "member2": "Rohit Bhomkar",
            "member3": "Harsh Jain",
            "member4": "Tarun Aswani",
            "guide": "Mr. Amit Singh",
            "coguide": "Mrs. Prajakta Pote",
            "description": "Automated answer assessment has gained significant traction in educational technology, aiming to reduce manual grading effort and ensure consistent evaluation. However, a critical limitation in many existing systems is the lack of explainability, making it difficult for students and educators to understand grading decisions. This project addresses that gap by designing an explainable automated assessment framework powered by large language models (LLMs), specifically Mistral AI. The system dynamically assigns evaluation weightage to key grading traits—Content Accuracy, Coherence & Structure, Vocabulary & Clarity, and Grammar & Language—based on question complexity. It then compares student responses with model answers, providing detailed feedback and improvement suggestions for each trait, along with a transparent score breakdown. By combining dynamic trait weighting with trait-specific commentary, the framework enhances both the fairness and interpretability of automated evaluations. This approach offers a promising step toward more trustworthy and pedagogically valuable AI-assisted assessment tools.",
            "github": "https://github.com/NeoZ666/Major-Project-BE",
            "demo": "https://www.youtube.com/embed/XTF2qz9sHSI",
            "domain": "Explainable AI",
            "Fundings Received": false,
            "member1 photo": "Khushi Bajaj",
            "member2 photo": "Rohit Bhomkar",
            "member3 photo": "Harsh Jain",
            "member4 photo": "Tarun Aswani",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1586847238amitsingh.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20Prajakta%20PotePP.jpg"
        },
        {
            "grpno": 16,
            "title": "AI-Driven Portfolio Optimization",
            "member1": "Akshay Gurnani",
            "member2": "Deepak Rajani",
            "member3": "Tanvi Sangale",
            "member4": "Piyush Batheja",
            "guide": "Mrs. Kanchan Chavan",
            "coguide": "Mrs. Bhagyashree",
            "description": "The project focuses on AI-driven portfolio optimization by predicting stock prices using LSTM models and selecting top-performing stocks from real-time Yahoo Finance data. 50,000 random portfolios are generated, and Mean-Variance Optimization is applied to select the portfolio with the best risk-return balance. Python libraries like NumPy, SciPy, and TensorFlow are used. The final output is an optimal, diversified investment portfolio.",
            "github": null,
            "demo": "https://www.youtube.com/embed/mBPXrH0utMY",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Akshay Gurnani",
            "member2 photo": "Deepak Rajani",
            "member3 photo": "Tanvi Sangale",
            "member4 photo": "Piyush Batheja",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585240237Kanchan%20Chavan.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20BhagyashreeIMG_20241218_195653.jpg"
        },
        {
            "grpno": 17,
            "title": "NeuroTumorAI:Prediction Segmentation and Classification Of Brain Tumors",
            "member1": "Gaurav Malpedi",
            "member2": "Suhanee Kandalkar",
            "member3": "Rohit Kshatriya",
            "member4": "Srirag Nair",
            "guide": "Mrs. Neeta Chavan",
            "coguide": "Mrs. Bhagyashree",
            "description": "Brain tumors are serious medical conditions where early and precise detection is vital for effective treatment. While predicting the stage of a tumor remains complex, our research focuses on developing a machine learning system capable of segmentation of different types of brain tumors based on MRI scans. By leveraging advanced algorithms, the system aims to assist in accurately identifying tumor types, thereby supporting doctors in making faster and more informed decisions, ultimately improving patient care and treatment planning.",
            "github": "https://github.com/DrizzyOVO/BeProjModel",
            "demo": "https://www.youtube.com/embed/H73-jodbesY",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Gaurav Malpedi",
            "member2 photo": "Suhanee Kandalkar",
            "member3 photo": "Rohit Kshatriya",
            "member4 photo": "Srirag Nair",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/1585252511Neeta%20Chavan.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/Mrs.%20BhagyashreeIMG_20241218_195653.jpg"
        },
        {
            "grpno": 18,
            "title": "AI Driven Early Detection Of Colorectal Cancer",
            "member1": "Sanika Dhuri",
            "member2": "Swayam Gaikwad",
            "member3": "Khyati Hegde",
            "member4": "Anjali Parwani",
            "guide": "Dr. Anjali Yeole",
            "coguide": "Mrs. Kusum Kardam",
            "description": "Colorectal cancer (CRC) is the second leading cause of cancer-related deaths globally, largely due to delayed diagnosis and reliance on manual histopathological analysis, which can be both time-consuming and prone to human error. To address this, we propose a two-stage AI-driven deep learning framework for automated CRC detection and risk assessment using histopathological and endoscopic imagery. In the first stage, a ResNet-50-based Convolutional Neural Network (CNN) classifies tissue images from the NCT-CRC-HE-100K dataset into nine categories, including tumor epithelium and stroma, with validation from CRC-VAL-HE-7K. If no cancer is detected, the second stage initiates, employing a Vision Transformer (ViT) model to analyze gastrointestinal images from the Kvasir-V2 dataset, identifying polyps—potential precursors to CRC.\nTo foster trust and transparency in medical decision-making, we incorporate Local Interpretable Model-Agnostic Explanations (LIME), which visually highlight critical regions influencing the model’s output. Additionally, a Retrieval-Augmented Generation (RAG) pipeline supports a Q&A system that retrieves contextual medical knowledge for enhanced user understanding. Results show the ResNet-50 model achieving over 90% classification accuracy and the ViT model reaching 93.5%, confirming the reliability of our framework. This pipeline not only improves diagnostic precision and reduces pathologist workload but also empowers early intervention through interpretable AI and real-time knowledge retrieval—making it a valuable asset for clinical decision support in colorectal cancer care.",
            "github": "https://github.com/Snika987/Final-Year-Project",
            "demo": "https://www.youtube.com/embed/5eqVIailUpc",
            "domain": "Deep Learning",
            "Fundings Received": false,
            "member1 photo": "Sanika Dhuri",
            "member2 photo": "Swayam Gaikwad",
            "member3 photo": "Khyati Hegde",
            "member4 photo": "Anjali Parwani",
            "guide photo": "https://vesit.ves.ac.in/storage/faculty/anjali_mam.jpg",
            "coguide photo": "https://vesit.ves.ac.in/storage/faculty/kusum.jpg"
        }
    ]
}